{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtBvI5_CTUPM"
      },
      "outputs": [],
      "source": [
        "# Import the Basic necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRzNLWxsSv9N"
      },
      "outputs": [],
      "source": [
        "# Importing the file Input.xlsx\n",
        "input = pd.read_excel('Input.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mZmlHGY9Tmkw",
        "outputId": "daae2257-784d-42eb-d7be-7f1a68f4d4f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            URL_ID                                                URL\n",
              "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
              "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
              "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
              "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
              "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0440515-6f2d-4b29-8253-bed77b9fbd5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blackassign0001</td>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blackassign0002</td>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blackassign0003</td>\n",
              "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blackassign0004</td>\n",
              "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blackassign0005</td>\n",
              "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0440515-6f2d-4b29-8253-bed77b9fbd5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0440515-6f2d-4b29-8253-bed77b9fbd5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0440515-6f2d-4b29-8253-bed77b9fbd5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8baef5f5-ae96-4c43-a1bf-e14f3fbf2aa8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8baef5f5-ae96-4c43-a1bf-e14f3fbf2aa8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8baef5f5-ae96-4c43-a1bf-e14f3fbf2aa8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "input",
              "summary": "{\n  \"name\": \"input\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"URL_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"blackassign0084\",\n          \"blackassign0054\",\n          \"blackassign0071\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\",\n          \"https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\",\n          \"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJqSGEOvVUJQ",
        "outputId": "bb4cb72d-cf82-494f-dbdb-fb5ca327d389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB51LfF8Vipc"
      },
      "source": [
        "- We have given 100 URL.\n",
        "- We have to extract the text content in each article and save it in .txt format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7PH2gu3zCHS",
        "outputId": "a2cde15e-2e01-4698-f378-f7535c7e76b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   URL_ID  100 non-null    object\n",
            " 1   URL     100 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.7+ KB\n"
          ]
        }
      ],
      "source": [
        "input.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCXftsaQVT6W"
      },
      "source": [
        "#### Extracting the Content of the Article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GffH3XaqT28Q"
      },
      "outputs": [],
      "source": [
        "# import BeautifulSoup library for extracting the Content from the post using the URL\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB0ElGajVPTl"
      },
      "outputs": [],
      "source": [
        "url = input['URL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDawVJ8WI2b",
        "outputId": "9d539148-50c4-4c42-a6f6-b07940abd59e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     https://insights.blackcoffer.com/rising-it-cit...\n",
              "1     https://insights.blackcoffer.com/rising-it-cit...\n",
              "2     https://insights.blackcoffer.com/internet-dema...\n",
              "3     https://insights.blackcoffer.com/rise-of-cyber...\n",
              "4     https://insights.blackcoffer.com/ott-platform-...\n",
              "                            ...                        \n",
              "95    https://insights.blackcoffer.com/what-is-the-r...\n",
              "96    https://insights.blackcoffer.com/impact-of-cov...\n",
              "97    https://insights.blackcoffer.com/contribution-...\n",
              "98    https://insights.blackcoffer.com/how-covid-19-...\n",
              "99    https://insights.blackcoffer.com/how-will-covi...\n",
              "Name: URL, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5chqKS5S95dH",
        "outputId": "7cc0261f-cd0d-4e15-bfa4-c9c3db61a4d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "url[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD2SwIL8WF7K"
      },
      "outputs": [],
      "source": [
        "# Sending an HTTP GET request to the URL\n",
        "page=requests.get(url[0])\n",
        "\n",
        "# Parsing the HTML content using BeautifulSoup with the 'html.parser'\n",
        "soup=BeautifulSoup(page.text,'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFbdH9H7U8HV"
      },
      "outputs": [],
      "source": [
        "# Extracting the title from the article\n",
        "\n",
        "try:\n",
        "  title = soup.find('h1',class_=\"entry-title\").text\n",
        "except:\n",
        "  title = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6a1a7TZZdAQX",
        "outputId": "33f06e04-a64c-449f-d99e-8a61ae8ea3cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHWOoaDUdDnk"
      },
      "outputs": [],
      "source": [
        "# Extracting the text-content from the article\n",
        "\n",
        "try:\n",
        "  text_content = soup.find('div', class_=\"td-post-content tagdiv-type\" ).text\n",
        "except:\n",
        "  text_content = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "yQHdKjHEdYwZ",
        "outputId": "97516a47-7953-4f05-d47b-bc5daa9649b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe have seen a huge development and dependence of people on technology in recent years. We have also seen the development of AI and ChatGPT in recent years. So it is a normal thing that we will become fully dependent on technology by 2040. Information technology will be a major power for all the developing nations. As a member of a developing nation, India is rapidly growing its IT base. It has also grown some IT cities which will be the major control centres for Information technology by 2040.\\nRising IT cities\\n\\nNoida:- Noida in Uttar Pradesh near New Delhi is an emerging IT sector now. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Noida has a market base of billions of dollars and is doing a great job of boosting the national economy. The establishment of so many software companies has made Noida an information technology hub.\\nGurgaon:- Gurgaon in Haryana is also an emerging IT hub. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Gurgaon has a market base of billions of dollars and is doing a great job of boosting the national economy.\\nBengaluru:- Bengaluru is called as the IT hub of India. It is also a smart city. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Bengaluru has a market base of billions of dollars and is doing a great job of boosting the national economy.\\n\\nKolkata:- Kolkata in West Bengal is an emerging major IT hub. The new Kolkata i.e. Saltlake Sector\\xa0 5, New town, Rajarhat area of Kolkata is a major IT hub. The government is giving the software companies land at almost free of cost to set up the companies there. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy.\\nImpact on Economy\\nThere is a huge impact of the rising IT cities on our economy. Some of the effects are-\\n\\nDemand:- The rising IT cities will greatly help to boost our economy. These will create a huge demand for raw materials. The products when ready will be a huge demand for the people too.\\nSupply:-– Supply means the fulfilment of demand. In a large and highly populous country like India, there is always a demand for finished products. If more IT cities do not develop, the companies cannot fulfil the needs and desires of the people of a populous country like India. As IT cities develop, more IT companies will come, which will supply more and more finished IT products to our people.\\nMarket: A market is a place where different economic agents like buyers and sellers interact with one another. In a populous country like India, there is a huge market. As IT cities will grow, more and more IT companies will come from across the world and more will the competition in the market increase. This will help consumers as they will get more and more differentiated products and the market will also run smoothly. A competitive market is always good and healthy. We can safely assume that our oligopoly market will surely tend to reach a perfectly competitive market by the year 2040.\\nRevenue:- As the market increases, more revenue will be generated. Now at present, the IT revenue of India is 245 million dollars, 19 million dollars more than the financial year 2022. If IT cities grow, then more companies will invest which leads to an increase in the IT market which in turn generates more revenue in India. We can expect that the IT revenue of India will cross or nearly tend to reach 10 billion dollars by 2040.\\n\\nImpact on Environment\\nThe rising IT cities will create a huge impact on the environment, the maximum of which will be harmful effects. The impact of rising IT cities on the environment is-\\n\\nDeforestation:- There will be cutting of trees in huge numbers to make the building of the IT companies which will cause great harm to the environment. The cutting of trees on a large scale will also cause mass degradation of forests.\\nMore carbon footprint:- The IT companies will generate more carbon footprint in the atmosphere. South Asian countries including India are known for their lower carbon footprint. But if the IT sector grows this way then we will also be at the same pace of generation of carbon footprint by 2040.\\nDeath of birds:- The cell phone and mobile towers by the telecom companies caused the death of birds which caused a great imbalance in the ecosystem. The number of sparrows has been reduced due to this phenomenon. If this goes on we can see the extinction of many bird species by 2040.\\n\\nImpact on infrastructure\\nThere are many contributions of the IT cities on infrastructure.\\xa0 They are-\\n\\nTransportation:- The rising IT cities need an excellent transport system for the supply of raw materials and delivery of the finished products into the market. So the transportation system develops in that area. So we have an excellent transport system by 2040.\\nNeed for a public transport system:- There is a need for a public transport system in the IT cities. As the IT cities are a source of employment and a huge population reside in these areas, there is an adequate need for public transport systems like buses, taxis etc. We hope that it will be improved by 2040.\\nWater supply:- As a huge number of people reside in the IT cities there is a need for adequate water supply to fulfil the needs of people as well as for industries. This will help us to find many new methods of water supply and conservation by 2040.\\nElectricity:- Electric supply is the lifeline of the sector. Without an electric supply, no machines will run and not even the IT cities will flourish. If the IT cities flourish this way, we going to have an excellent electric supply by 2040.\\nHealthcare:- As a large number of people reside in IT cities, there is a need for proper health infrastructure and healthcare facilities for the people. So with the growth of IT cities, our healthcare system will also improve by 2040.\\nEducation:- Education is the primary key or core of any nation. There must be proper education and training centres in those IT cities to fulfil the people’s demands.\\xa0 So with the growth of IT cities, the education system will also develop by 2040. Our education is also going to be skill-oriented.\\n\\nImpact on city life\\nWith the growth of IT cities, more people will get jobs and will earn more. So the purchasing power of the people will increase. People will lead a better lifestyle. They will buy things of good brand value. The tastes and preferences of people will also change. The human development index is going to increase. People will buy good quality food and good quality cars. So the food, automobile and many other industries are going to increase. So there will be a huge impact on city life by 2040.\\nBlackcoffer Insights 47: Arka Mukhopadhyay, West Bengal University Of Animal And Fishery Sciences \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "text_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVcA2vKsdZ0m"
      },
      "outputs": [],
      "source": [
        "# Function for creating text file\n",
        "\n",
        "def write_text_file( file_path, title, text_content ):\n",
        "    # Open the file in 'write' mode\n",
        "    with open(file_path, 'w') as file:\n",
        "        # Write the title to the file\n",
        "        file.write(f\"{title}\\n\\n\")\n",
        "\n",
        "        # Write the text content to the file\n",
        "        file.write(text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgwTpH54Aou5",
        "outputId": "fc92e687-4459-4e04-e0c6-65972ef66af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'blackassign0001.txt' has been created.\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "file_path = f\"{input['URL_ID'][0]}.txt\"\n",
        "\n",
        "# Call the function to write the text file\n",
        "write_text_file(file_path, title, text_content)\n",
        "\n",
        "print(f\"File '{file_path}' has been created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px1c7063vhTe"
      },
      "outputs": [],
      "source": [
        "# Function for creating text file\n",
        "def write_text_file(file_name, title, text_content):\n",
        "    # Open the file in 'write' mode\n",
        "    with open(file_name, 'w') as file:\n",
        "        # Write the title to the file\n",
        "        file.write(f\"{title}\\n\\n\")\n",
        "\n",
        "        # Write the text content to the file\n",
        "        file.write(text_content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHVo1uqjAohs"
      },
      "outputs": [],
      "source": [
        "# Function to get the text in each article\n",
        "\n",
        "def get_text_file( url, url_id ):\n",
        "\n",
        "  try:\n",
        "      # Sending an HTTP GET request to the URL\n",
        "      page = requests.get(url)\n",
        "      page.raise_for_status()  # Raises an HTTPError for non-2xx responses\n",
        "      # Proceed with parsing or other operations on response content\n",
        "      # print(\"Page retrieved successfully!\")\n",
        "      # Parsing the HTML content using BeautifulSoup with the 'html.parser'\n",
        "      soup = BeautifulSoup(page.text,'html.parser')\n",
        "\n",
        "      # Extracting the title from the article\n",
        "      try:\n",
        "          title = soup.find('h1',class_=\"entry-title\").text\n",
        "      except AttributeError:\n",
        "          # Handle the specific exception (AttributeError) raised by soup.find() if element is not found\n",
        "          try:\n",
        "            title = soup.find('h1',class_ =\"tdb-title-text\" ).text\n",
        "          except AttributeError:\n",
        "              # Handle another specific exception (AttributeError) for the fallback case\n",
        "              title = np.nan  # Use np.nan as the default value if both finds fail\n",
        "\n",
        "    # Extracting the text-content from the article\n",
        "      try:\n",
        "          text_content = soup.find('div', class_=\"td-post-content tagdiv-type\").text\n",
        "      except AttributeError:\n",
        "          # Handle the specific exception (AttributeError) raised by soup.find() if element is not found\n",
        "          try:\n",
        "              text_content = soup.find('div', class_=\"td_block_wrap tdb_single_content tdi_130 td-pb-border-top td_block_template_1 td-post-content tagdiv-type\").text\n",
        "          except AttributeError:\n",
        "              # Handle another specific exception (AttributeError) for the fallback case\n",
        "              text_content = np.nan  # Use np.nan as the default value if both finds fail\n",
        "\n",
        "      # File name\n",
        "      file_name = f\"{url_id}.txt\"\n",
        "\n",
        "      # Call the function to write the text file\n",
        "      write_text_file( file_name, title, text_content)\n",
        "\n",
        "      print(f\"File '{url_id}' has been created.\")\n",
        "\n",
        "\n",
        "\n",
        "# Error Handling if the page is not found   ( page for url 35 is not found. )\n",
        "  except requests.exceptions.HTTPError as errh:\n",
        "      # Handle HTTP errors (status codes 4xx and 5xx)\n",
        "      print(f\"HTTP Error: {errh}\")\n",
        "\n",
        "      # File name\n",
        "      file_name = f\"{url_id}.txt\"\n",
        "\n",
        "      # title will be blank\n",
        "      title     = ''\n",
        "\n",
        "      # Error will be added to the text_content\n",
        "      text_content = f\"HTTP Error: {errh}\"\n",
        "\n",
        "      # Call the function to write the text file\n",
        "      write_text_file( file_name, title, text_content)\n",
        "\n",
        "      print(f\"File '{url_id}' has been created.\")\n",
        "\n",
        "\n",
        "  except requests.exceptions.RequestException as err:\n",
        "      # Handle other types of request exceptions (e.g., network errors)\n",
        "      print(f\"Request Error: {err}\")\n",
        "\n",
        "      # File name\n",
        "      file_name = f\"{url_id}.txt\"\n",
        "\n",
        "      # title will be blank\n",
        "      title     = ''\n",
        "\n",
        "      # Error will be added to the text_content\n",
        "      text_content = f\"HTTP Error: {errh}\"\n",
        "\n",
        "      # Call the function to write the text file\n",
        "      write_text_file( file_name, title, text_content)\n",
        "\n",
        "      print(f\"File '{url_id}' has been created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGZtiT8xB7Rf"
      },
      "outputs": [],
      "source": [
        "# get_text_file(input['URL'][35], input['URL_ID'][35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-INMGMxCFqo",
        "outputId": "201f32da-115f-4393-f942-6c318d40bc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'blackassign0001' has been created.\n",
            "File 'blackassign0002' has been created.\n",
            "File 'blackassign0003' has been created.\n",
            "File 'blackassign0004' has been created.\n",
            "File 'blackassign0005' has been created.\n",
            "File 'blackassign0006' has been created.\n",
            "File 'blackassign0007' has been created.\n",
            "File 'blackassign0008' has been created.\n",
            "File 'blackassign0009' has been created.\n",
            "File 'blackassign0010' has been created.\n",
            "File 'blackassign0011' has been created.\n",
            "File 'blackassign0012' has been created.\n",
            "File 'blackassign0013' has been created.\n",
            "File 'blackassign0014' has been created.\n",
            "File 'blackassign0015' has been created.\n",
            "File 'blackassign0016' has been created.\n",
            "File 'blackassign0017' has been created.\n",
            "File 'blackassign0018' has been created.\n",
            "File 'blackassign0019' has been created.\n",
            "File 'blackassign0020' has been created.\n",
            "File 'blackassign0021' has been created.\n",
            "File 'blackassign0022' has been created.\n",
            "File 'blackassign0023' has been created.\n",
            "File 'blackassign0024' has been created.\n",
            "File 'blackassign0025' has been created.\n",
            "File 'blackassign0026' has been created.\n",
            "File 'blackassign0027' has been created.\n",
            "File 'blackassign0028' has been created.\n",
            "File 'blackassign0029' has been created.\n",
            "File 'blackassign0030' has been created.\n",
            "File 'blackassign0031' has been created.\n",
            "File 'blackassign0032' has been created.\n",
            "File 'blackassign0033' has been created.\n",
            "File 'blackassign0034' has been created.\n",
            "File 'blackassign0035' has been created.\n",
            "HTTP Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "File 'blackassign0036' has been created.\n",
            "File 'blackassign0037' has been created.\n",
            "File 'blackassign0038' has been created.\n",
            "File 'blackassign0039' has been created.\n",
            "File 'blackassign0040' has been created.\n",
            "File 'blackassign0041' has been created.\n",
            "File 'blackassign0042' has been created.\n",
            "File 'blackassign0043' has been created.\n",
            "File 'blackassign0044' has been created.\n",
            "File 'blackassign0045' has been created.\n",
            "File 'blackassign0046' has been created.\n",
            "File 'blackassign0047' has been created.\n",
            "File 'blackassign0048' has been created.\n",
            "HTTP Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "File 'blackassign0049' has been created.\n",
            "File 'blackassign0050' has been created.\n",
            "File 'blackassign0051' has been created.\n",
            "File 'blackassign0052' has been created.\n",
            "File 'blackassign0053' has been created.\n",
            "File 'blackassign0054' has been created.\n",
            "File 'blackassign0055' has been created.\n",
            "File 'blackassign0056' has been created.\n",
            "File 'blackassign0057' has been created.\n",
            "File 'blackassign0058' has been created.\n",
            "File 'blackassign0059' has been created.\n",
            "File 'blackassign0060' has been created.\n",
            "File 'blackassign0061' has been created.\n",
            "File 'blackassign0062' has been created.\n",
            "File 'blackassign0063' has been created.\n",
            "File 'blackassign0064' has been created.\n",
            "File 'blackassign0065' has been created.\n",
            "File 'blackassign0066' has been created.\n",
            "File 'blackassign0067' has been created.\n",
            "File 'blackassign0068' has been created.\n",
            "File 'blackassign0069' has been created.\n",
            "File 'blackassign0070' has been created.\n",
            "File 'blackassign0071' has been created.\n",
            "File 'blackassign0072' has been created.\n",
            "File 'blackassign0073' has been created.\n",
            "File 'blackassign0074' has been created.\n",
            "File 'blackassign0075' has been created.\n",
            "File 'blackassign0076' has been created.\n",
            "File 'blackassign0077' has been created.\n",
            "File 'blackassign0078' has been created.\n",
            "File 'blackassign0079' has been created.\n",
            "File 'blackassign0080' has been created.\n",
            "File 'blackassign0081' has been created.\n",
            "File 'blackassign0082' has been created.\n",
            "File 'blackassign0083' has been created.\n",
            "File 'blackassign0084' has been created.\n",
            "File 'blackassign0085' has been created.\n",
            "File 'blackassign0086' has been created.\n",
            "File 'blackassign0087' has been created.\n",
            "File 'blackassign0088' has been created.\n",
            "File 'blackassign0089' has been created.\n",
            "File 'blackassign0090' has been created.\n",
            "File 'blackassign0091' has been created.\n",
            "File 'blackassign0092' has been created.\n",
            "File 'blackassign0093' has been created.\n",
            "File 'blackassign0094' has been created.\n",
            "File 'blackassign0095' has been created.\n",
            "File 'blackassign0096' has been created.\n",
            "File 'blackassign0097' has been created.\n",
            "File 'blackassign0098' has been created.\n",
            "File 'blackassign0099' has been created.\n",
            "File 'blackassign0100' has been created.\n"
          ]
        }
      ],
      "source": [
        "# Extracting the text_content for all the URL provided in Input.xlsx file and saving them individually with URL_ID.txt format\n",
        "\n",
        "for i in range( input.shape[0]):\n",
        "\n",
        "  # Calling the above function get_text_file for each url\n",
        "  get_text_file( input['URL'][i], input['URL_ID'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlXnARNpKB7b"
      },
      "outputs": [],
      "source": [
        "# class=\"td_block_wrap tdb_single_content tdi_130 td-pb-border-top td_block_template_1 td-post-content tagdiv-type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08cAfSGquw4R",
        "outputId": "8d281ec5-a989-40b3-8473-a1ca5f85a36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "url = input['URL'][35]\n",
        "\n",
        "\n",
        "try:\n",
        "    page = requests.get(url)\n",
        "    page.raise_for_status()  # Raises an HTTPError for non-2xx responses\n",
        "    # Proceed with parsing or other operations on response content\n",
        "    print(\"Page retrieved successfully!\")\n",
        "except requests.exceptions.HTTPError as errh:\n",
        "    # Handle HTTP errors (status codes 4xx and 5xx)\n",
        "    print(f\"HTTP Error: {errh}\")\n",
        "except requests.exceptions.RequestException as err:\n",
        "    # Handle other types of request exceptions (e.g., network errors)\n",
        "    print(f\"Request Error: {err}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY3RPMMeG5JP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-uaKgb21CL5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LoxCylffzTn"
      },
      "source": [
        "## **Text Processing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDlFUHe6g35z"
      },
      "source": [
        "##### Applying all the steps of NLP for a single .txt file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owcO9JC7gDYd"
      },
      "outputs": [],
      "source": [
        "# Reading the text file\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    encodings = ['utf-8', 'latin-1', 'iso-8859-1']\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
        "                content = file.read()\n",
        "                print(f\"File successfully read with encoding {encoding}:\")\n",
        "                # print(content)\n",
        "                return content\n",
        "        except FileNotFoundError:\n",
        "            print(f\"The file at {file_path} was not found.\")\n",
        "            return f\"The file at {file_path} was not found.\"\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(f\"An encoding error occurred with {encoding}: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while reading the file: {e}\")\n",
        "\n",
        "    print(\"Failed to read the file with all attempted encodings.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NemtjEKumZ80",
        "outputId": "0bcc6885-605f-4a8a-993b-edfdde7f15f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully read with encoding utf-8:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = \"blackassign0001.txt\"\n",
        "raw_text_content  = read_text_file(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "8oI2evLK3mNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "V4vJwHEkfytD",
        "outputId": "e27e6f37-1029-4114-f354-0405867b70ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\\n\\n\\nWe have seen a huge development and dependence of people on technology in recent years. We have also seen the development of AI and ChatGPT in recent years. So it is a normal thing that we will become fully dependent on technology by 2040. Information technology will be a major power for all the developing nations. As a member of a developing nation, India is rapidly growing its IT base. It has also grown some IT cities which will be the major control centres for Information technology by 2040.\\nRising IT cities\\n\\nNoida:- Noida in Uttar Pradesh near New Delhi is an emerging IT sector now. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Noida has a market base of billions of dollars and is doing a great job of boosting the national economy. The establishment of so many software companies has made Noida an information technology hub.\\nGurgaon:- Gurgaon in Haryana is also an emerging IT hub. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Gurgaon has a market base of billions of dollars and is doing a great job of boosting the national economy.\\nBengaluru:- Bengaluru is called as the IT hub of India. It is also a smart city. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Bengaluru has a market base of billions of dollars and is doing a great job of boosting the national economy.\\n\\nKolkata:- Kolkata in West Bengal is an emerging major IT hub. The new Kolkata i.e. Saltlake Sector\\xa0 5, New town, Rajarhat area of Kolkata is a major IT hub. The government is giving the software companies land at almost free of cost to set up the companies there. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy.\\nImpact on Economy\\nThere is a huge impact of the rising IT cities on our economy. Some of the effects are-\\n\\nDemand:- The rising IT cities will greatly help to boost our economy. These will create a huge demand for raw materials. The products when ready will be a huge demand for the people too.\\nSupply:-– Supply means the fulfilment of demand. In a large and highly populous country like India, there is always a demand for finished products. If more IT cities do not develop, the companies cannot fulfil the needs and desires of the people of a populous country like India. As IT cities develop, more IT companies will come, which will supply more and more finished IT products to our people.\\nMarket: A market is a place where different economic agents like buyers and sellers interact with one another. In a populous country like India, there is a huge market. As IT cities will grow, more and more IT companies will come from across the world and more will the competition in the market increase. This will help consumers as they will get more and more differentiated products and the market will also run smoothly. A competitive market is always good and healthy. We can safely assume that our oligopoly market will surely tend to reach a perfectly competitive market by the year 2040.\\nRevenue:- As the market increases, more revenue will be generated. Now at present, the IT revenue of India is 245 million dollars, 19 million dollars more than the financial year 2022. If IT cities grow, then more companies will invest which leads to an increase in the IT market which in turn generates more revenue in India. We can expect that the IT revenue of India will cross or nearly tend to reach 10 billion dollars by 2040.\\n\\nImpact on Environment\\nThe rising IT cities will create a huge impact on the environment, the maximum of which will be harmful effects. The impact of rising IT cities on the environment is-\\n\\nDeforestation:- There will be cutting of trees in huge numbers to make the building of the IT companies which will cause great harm to the environment. The cutting of trees on a large scale will also cause mass degradation of forests.\\nMore carbon footprint:- The IT companies will generate more carbon footprint in the atmosphere. South Asian countries including India are known for their lower carbon footprint. But if the IT sector grows this way then we will also be at the same pace of generation of carbon footprint by 2040.\\nDeath of birds:- The cell phone and mobile towers by the telecom companies caused the death of birds which caused a great imbalance in the ecosystem. The number of sparrows has been reduced due to this phenomenon. If this goes on we can see the extinction of many bird species by 2040.\\n\\nImpact on infrastructure\\nThere are many contributions of the IT cities on infrastructure.\\xa0 They are-\\n\\nTransportation:- The rising IT cities need an excellent transport system for the supply of raw materials and delivery of the finished products into the market. So the transportation system develops in that area. So we have an excellent transport system by 2040.\\nNeed for a public transport system:- There is a need for a public transport system in the IT cities. As the IT cities are a source of employment and a huge population reside in these areas, there is an adequate need for public transport systems like buses, taxis etc. We hope that it will be improved by 2040.\\nWater supply:- As a huge number of people reside in the IT cities there is a need for adequate water supply to fulfil the needs of people as well as for industries. This will help us to find many new methods of water supply and conservation by 2040.\\nElectricity:- Electric supply is the lifeline of the sector. Without an electric supply, no machines will run and not even the IT cities will flourish. If the IT cities flourish this way, we going to have an excellent electric supply by 2040.\\nHealthcare:- As a large number of people reside in IT cities, there is a need for proper health infrastructure and healthcare facilities for the people. So with the growth of IT cities, our healthcare system will also improve by 2040.\\nEducation:- Education is the primary key or core of any nation. There must be proper education and training centres in those IT cities to fulfil the people’s demands.\\xa0 So with the growth of IT cities, the education system will also develop by 2040. Our education is also going to be skill-oriented.\\n\\nImpact on city life\\nWith the growth of IT cities, more people will get jobs and will earn more. So the purchasing power of the people will increase. People will lead a better lifestyle. They will buy things of good brand value. The tastes and preferences of people will also change. The human development index is going to increase. People will buy good quality food and good quality cars. So the food, automobile and many other industries are going to increase. So there will be a huge impact on city life by 2040.\\nBlackcoffer Insights 47: Arka Mukhopadhyay, West Bengal University Of Animal And Fishery Sciences \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# View of the text content in the file\n",
        "raw_text_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFKmHlZ_fypq"
      },
      "outputs": [],
      "source": [
        "# # Applying .lower() function for Converting the whole text into Lowercase.\n",
        "# text_content = text_content.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0kaPJoWiZ0f"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations\n",
        "\n",
        "# extracting the string that contain all punctuation marks\n",
        "Punctuations = '''`~!@#$%^&*()_+-=[]\\{}|;':\",./<>?'''\n",
        "\n",
        "def lowercasing_and_remove_punctuation(text):\n",
        "\n",
        "  # Applying .lower() function for Converting the whole text into Lowercase.\n",
        "  text = text.lower()\n",
        "\n",
        "  new_text = ''\n",
        "  for char in text:\n",
        "    if char not in Punctuations:\n",
        "      new_text = new_text + char\n",
        "  return new_text\n",
        "\n",
        "# applying the function to remove the punctuation\n",
        "text_content = lowercasing_and_remove_punctuation( raw_text_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxlapam1itMx"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "#  Defining the function for removing the URL and digits\n",
        "def remove_url_and_digits(text):\n",
        "\n",
        "  words = text.split()\n",
        "  new_words = []\n",
        "\n",
        "  for word in words :\n",
        "    # Checking the URL in the words\n",
        "    if not (word.startswith('http://') or word.startswith('https://') or word.startswith('www.')):\n",
        "\n",
        "      # Checking the Digits present in the words\n",
        "      if word.isalpha():\n",
        "\n",
        "        #appending the word to the list of new_words\n",
        "        new_words.append( word )\n",
        "\n",
        "  return ' '.join(new_words)                        # join the words using whitespaces and returning the text\n",
        "\n",
        "# applying the function to remove the punctuation\n",
        "text_content = remove_url_and_digits( text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "jf140_u9fymm",
        "outputId": "a5be7aef-5d76-4a0e-c465-fb1cba3838d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rising it cities and its impact on the economy environment infrastructure and city life by the year we have seen a huge development and dependence of people on technology in recent years we have also seen the development of ai and chatgpt in recent years so it is a normal thing that we will become fully dependent on technology by information technology will be a major power for all the developing nations as a member of a developing nation india is rapidly growing its it base it has also grown some it cities which will be the major control centres for information technology by rising it cities noida noida in uttar pradesh near new delhi is an emerging it sector now many large companies like google microsoft ibm infosys and others have set up their companies here noida has a market base of billions of dollars and is doing a great job of boosting the national economy the establishment of so many software companies has made noida an information technology hub gurgaon gurgaon in haryana is also an emerging it hub many large companies like google microsoft ibm infosys and others have set up their companies here gurgaon has a market base of billions of dollars and is doing a great job of boosting the national economy bengaluru bengaluru is called as the it hub of india it is also a smart city many large companies like google microsoft ibm infosys and others have set up their companies here bengaluru has a market base of billions of dollars and is doing a great job of boosting the national economy kolkata kolkata in west bengal is an emerging major it hub the new kolkata ie saltlake sector new town rajarhat area of kolkata is a major it hub the government is giving the software companies land at almost free of cost to set up the companies there many large companies like google microsoft ibm infosys and others have set up their companies here kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy impact on economy there is a huge impact of the rising it cities on our economy some of the effects are demand the rising it cities will greatly help to boost our economy these will create a huge demand for raw materials the products when ready will be a huge demand for the people too supply means the fulfilment of demand in a large and highly populous country like india there is always a demand for finished products if more it cities do not develop the companies cannot fulfil the needs and desires of the people of a populous country like india as it cities develop more it companies will come which will supply more and more finished it products to our people market a market is a place where different economic agents like buyers and sellers interact with one another in a populous country like india there is a huge market as it cities will grow more and more it companies will come from across the world and more will the competition in the market increase this will help consumers as they will get more and more differentiated products and the market will also run smoothly a competitive market is always good and healthy we can safely assume that our oligopoly market will surely tend to reach a perfectly competitive market by the year revenue as the market increases more revenue will be generated now at present the it revenue of india is million dollars million dollars more than the financial year if it cities grow then more companies will invest which leads to an increase in the it market which in turn generates more revenue in india we can expect that the it revenue of india will cross or nearly tend to reach billion dollars by impact on environment the rising it cities will create a huge impact on the environment the maximum of which will be harmful effects the impact of rising it cities on the environment is deforestation there will be cutting of trees in huge numbers to make the building of the it companies which will cause great harm to the environment the cutting of trees on a large scale will also cause mass degradation of forests more carbon footprint the it companies will generate more carbon footprint in the atmosphere south asian countries including india are known for their lower carbon footprint but if the it sector grows this way then we will also be at the same pace of generation of carbon footprint by death of birds the cell phone and mobile towers by the telecom companies caused the death of birds which caused a great imbalance in the ecosystem the number of sparrows has been reduced due to this phenomenon if this goes on we can see the extinction of many bird species by impact on infrastructure there are many contributions of the it cities on infrastructure they are transportation the rising it cities need an excellent transport system for the supply of raw materials and delivery of the finished products into the market so the transportation system develops in that area so we have an excellent transport system by need for a public transport system there is a need for a public transport system in the it cities as the it cities are a source of employment and a huge population reside in these areas there is an adequate need for public transport systems like buses taxis etc we hope that it will be improved by water supply as a huge number of people reside in the it cities there is a need for adequate water supply to fulfil the needs of people as well as for industries this will help us to find many new methods of water supply and conservation by electricity electric supply is the lifeline of the sector without an electric supply no machines will run and not even the it cities will flourish if the it cities flourish this way we going to have an excellent electric supply by healthcare as a large number of people reside in it cities there is a need for proper health infrastructure and healthcare facilities for the people so with the growth of it cities our healthcare system will also improve by education education is the primary key or core of any nation there must be proper education and training centres in those it cities to fulfil the demands so with the growth of it cities the education system will also develop by our education is also going to be skilloriented impact on city life with the growth of it cities more people will get jobs and will earn more so the purchasing power of the people will increase people will lead a better lifestyle they will buy things of good brand value the tastes and preferences of people will also change the human development index is going to increase people will buy good quality food and good quality cars so the food automobile and many other industries are going to increase so there will be a huge impact on city life by blackcoffer insights arka mukhopadhyay west bengal university of animal and fishery sciences'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "text_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC2wCDabjQy_"
      },
      "source": [
        "##### **Cleaning using Stop Words Lists**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPkMU7eajuUC",
        "outputId": "229b5253-3e6f-460b-951a-d505a6cd1369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n"
          ]
        }
      ],
      "source": [
        "# Creatiing stopwords list for Given stopword list using the same read_text_file fucntion for rrading text files\n",
        "\n",
        "stopwords_auditor         = read_text_file('StopWords_Auditor.txt')\n",
        "stopwords_currencies      = read_text_file('StopWords_Currencies.txt')\n",
        "stopwords_datesandnumbers = read_text_file('StopWords_DatesandNumbers.txt')\n",
        "stopwords_generic         = read_text_file('StopWords_Generic.txt')\n",
        "stopwords_genericlong     = read_text_file('StopWords_GenericLong.txt')\n",
        "stopwords_geographic      = read_text_file('StopWords_Geographic.txt')\n",
        "stopwords_names           = read_text_file('StopWords_Names.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS2JUaQoycIW"
      },
      "outputs": [],
      "source": [
        "# lowercasing the stopwords & Splitting the words in stopwords_auditior.txt file\n",
        "import re\n",
        "\n",
        "def lowercasing_and_split_string_multiple_delimiters(text):\n",
        "    # lowercasing the stopwords text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Define the delimiters you want to split by\n",
        "    delimiters = r'[|\\n ]+'  # This regex splits by |, \\n and space\n",
        "\n",
        "    # Use re.split() to split the string by the defined delimiters\n",
        "    result = re.split(delimiters, text)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMlCOfLYyrXy"
      },
      "outputs": [],
      "source": [
        "# Applying lowercasing_and_split_string_multiple_delimiters to all stopwords.txt\n",
        "stopwords_auditor = lowercasing_and_split_string_multiple_delimiters(stopwords_auditor)\n",
        "stopwords_currencies = lowercasing_and_split_string_multiple_delimiters(stopwords_currencies)\n",
        "stopwords_datesandnumbers = lowercasing_and_split_string_multiple_delimiters(stopwords_datesandnumbers)\n",
        "stopwords_generic = lowercasing_and_split_string_multiple_delimiters(stopwords_generic)\n",
        "stopwords_genericlong = lowercasing_and_split_string_multiple_delimiters(stopwords_genericlong)\n",
        "stopwords_geographic = lowercasing_and_split_string_multiple_delimiters(stopwords_geographic)\n",
        "stopwords_names = lowercasing_and_split_string_multiple_delimiters(stopwords_names)\n",
        "\n",
        "\n",
        "# Creating a single list by Combining  all the above stopwords_lists\n",
        "combined_stopwords = stopwords_auditor + stopwords_currencies + stopwords_datesandnumbers + stopwords_generic + stopwords_genericlong + stopwords_geographic + stopwords_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1vRynAr4VxM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AguhwEYk-Y2"
      },
      "outputs": [],
      "source": [
        "# Removing the stopwords from the text_content\n",
        "def remove_stopwords(text):\n",
        "\n",
        "# removing stopwords\n",
        "  new_words = []\n",
        "  for word in text.split():\n",
        "    if word not in combined_stopwords:\n",
        "      new_words.append(word)\n",
        "\n",
        "  return ' '.join(new_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4An-i_7xqeyL"
      },
      "outputs": [],
      "source": [
        " # Applying remove_stopword function to remove stopwords from the text_content\n",
        " text_content = remove_stopwords(text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrgM-HOExm0V",
        "outputId": "c3484933-b189-4d01-d015-28e5b28a896c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rising impact economy environment infrastructure life huge development dependence people technology recent years development chatgpt recent years normal thing fully dependent technology information technology developing member developing rapidly growing base grown control centres information technology rising noida noida uttar pradesh emerging sector companies google microsoft ibm infosys set companies noida market base billions dollars great job boosting national economy establishment software companies made noida information technology hub gurgaon gurgaon haryana emerging hub companies google microsoft ibm infosys set companies gurgaon market base billions dollars great job boosting national economy bengaluru bengaluru called hub companies google microsoft ibm infosys set companies bengaluru market base billions dollars great job boosting national economy kolkata kolkata bengal emerging hub kolkata saltlake sector town rajarhat area kolkata hub government giving software companies cost set companies companies google microsoft ibm infosys set companies kolkata market base billions dollars great job boosting national economy impact economy huge impact rising economy effects demand rising greatly boost economy create huge demand raw materials products huge demand people supply fulfilment demand highly populous demand finished products develop companies fulfil desires people populous develop companies supply finished products people market market economic agents buyers interact populous huge market companies world competition market increase consumers differentiated products market run smoothly competitive market healthy safely assume oligopoly market surely tend reach perfectly competitive market revenue market increases revenue generated present revenue dollars dollars financial companies invest leads increase market turn generates revenue expect revenue tend reach dollars impact environment rising create huge impact environment maximum harmful effects impact rising environment deforestation cutting trees huge make building companies great harm environment cutting trees scale mass degradation forests carbon footprint companies generate carbon footprint atmosphere asian including carbon footprint sector grows generation carbon footprint death birds cell phone mobile towers telecom companies caused death birds caused great imbalance ecosystem number sparrows reduced due phenomenon extinction species impact infrastructure contributions infrastructure transportation rising excellent transport system supply raw materials delivery finished products market transportation system develops area excellent transport system public transport system public transport system source employment huge population reside areas adequate public transport systems buses taxis improved water supply huge number people reside adequate water supply fulfil people industries find methods water supply conservation electricity electric supply lifeline sector electric supply machines run flourish flourish excellent electric supply healthcare number people reside proper health infrastructure healthcare facilities people growth healthcare system improve education education primary proper education training centres fulfil demands growth education system develop education skilloriented impact life growth people jobs earn purchasing people increase people lead lifestyle buy things tastes preferences people change human development index increase people buy quality food quality cars food automobile industries increase huge impact life blackcoffer insights arka mukhopadhyay bengal university animal fishery sciences'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        " text_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQD00DJ_9Mx1"
      },
      "source": [
        "##### Creating the list of Positive and Negative words lists\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlDFIBJ01IC3",
        "outputId": "64044d25-1d70-41c1-d37d-fe7c570ab7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully read with encoding utf-8:\n",
            "File successfully read with encoding utf-8:\n"
          ]
        }
      ],
      "source": [
        "# Creatiing stopwords list for Given stopword list using the same read_text_file fucntion for rrading text files\n",
        "\n",
        "positive_words         = read_text_file('positive-words.txt')\n",
        "\n",
        "negative_words         = read_text_file('negative-words.txt')\n",
        "\n",
        "\n",
        "\n",
        "# Applying lowercasing_and_split_string_multiple_delimiters to all positive_words & negative_words\n",
        "\n",
        "positive_words = lowercasing_and_split_string_multiple_delimiters(positive_words)\n",
        "\n",
        "negative_words = lowercasing_and_split_string_multiple_delimiters(negative_words)\n",
        "\n",
        "\n",
        "\n",
        "# Creating a Positive_words_dict & Negative_words_dict\n",
        "\n",
        "positive_words_dict = {}\n",
        "negative_words_dict = {}\n",
        "\n",
        "for word in positive_words:\n",
        "  positive_words_dict[word] = 0\n",
        "\n",
        "for word in negative_words:\n",
        "  negative_words_dict[word] = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muUXjq_BOA9"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdF8JDynAPAF",
        "outputId": "9715e054-55ae-44cb-88d4-8f8225305436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# word tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def text_tokenization(text):\n",
        "  # tokenizing the text\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI4Jy53yhrB_"
      },
      "outputs": [],
      "source": [
        "text_content_tokens = text_tokenization(text_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ADFRSntDDlK"
      },
      "source": [
        "#### 1. Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9rnsD-TvDyTa",
        "outputId": "1eaadf1f-3732-4877-b3b3-009971a31134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a+': 0,\n",
              " 'abound': 0,\n",
              " 'abounds': 0,\n",
              " 'abundance': 0,\n",
              " 'abundant': 0,\n",
              " 'accessable': 0,\n",
              " 'accessible': 0,\n",
              " 'acclaim': 0,\n",
              " 'acclaimed': 0,\n",
              " 'acclamation': 0,\n",
              " 'accolade': 0,\n",
              " 'accolades': 0,\n",
              " 'accommodative': 0,\n",
              " 'accomodative': 0,\n",
              " 'accomplish': 0,\n",
              " 'accomplished': 0,\n",
              " 'accomplishment': 0,\n",
              " 'accomplishments': 0,\n",
              " 'accurate': 0,\n",
              " 'accurately': 0,\n",
              " 'achievable': 0,\n",
              " 'achievement': 0,\n",
              " 'achievements': 0,\n",
              " 'achievible': 0,\n",
              " 'acumen': 0,\n",
              " 'adaptable': 0,\n",
              " 'adaptive': 0,\n",
              " 'adequate': 0,\n",
              " 'adjustable': 0,\n",
              " 'admirable': 0,\n",
              " 'admirably': 0,\n",
              " 'admiration': 0,\n",
              " 'admire': 0,\n",
              " 'admirer': 0,\n",
              " 'admiring': 0,\n",
              " 'admiringly': 0,\n",
              " 'adorable': 0,\n",
              " 'adore': 0,\n",
              " 'adored': 0,\n",
              " 'adorer': 0,\n",
              " 'adoring': 0,\n",
              " 'adoringly': 0,\n",
              " 'adroit': 0,\n",
              " 'adroitly': 0,\n",
              " 'adulate': 0,\n",
              " 'adulation': 0,\n",
              " 'adulatory': 0,\n",
              " 'advanced': 0,\n",
              " 'advantage': 0,\n",
              " 'advantageous': 0,\n",
              " 'advantageously': 0,\n",
              " 'advantages': 0,\n",
              " 'adventuresome': 0,\n",
              " 'adventurous': 0,\n",
              " 'advocate': 0,\n",
              " 'advocated': 0,\n",
              " 'advocates': 0,\n",
              " 'affability': 0,\n",
              " 'affable': 0,\n",
              " 'affably': 0,\n",
              " 'affectation': 0,\n",
              " 'affection': 0,\n",
              " 'affectionate': 0,\n",
              " 'affinity': 0,\n",
              " 'affirm': 0,\n",
              " 'affirmation': 0,\n",
              " 'affirmative': 0,\n",
              " 'affluence': 0,\n",
              " 'affluent': 0,\n",
              " 'afford': 0,\n",
              " 'affordable': 0,\n",
              " 'affordably': 0,\n",
              " 'afordable': 0,\n",
              " 'agile': 0,\n",
              " 'agilely': 0,\n",
              " 'agility': 0,\n",
              " 'agreeable': 0,\n",
              " 'agreeableness': 0,\n",
              " 'agreeably': 0,\n",
              " 'all-around': 0,\n",
              " 'alluring': 0,\n",
              " 'alluringly': 0,\n",
              " 'altruistic': 0,\n",
              " 'altruistically': 0,\n",
              " 'amaze': 0,\n",
              " 'amazed': 0,\n",
              " 'amazement': 0,\n",
              " 'amazes': 0,\n",
              " 'amazing': 0,\n",
              " 'amazingly': 0,\n",
              " 'ambitious': 0,\n",
              " 'ambitiously': 0,\n",
              " 'ameliorate': 0,\n",
              " 'amenable': 0,\n",
              " 'amenity': 0,\n",
              " 'amiability': 0,\n",
              " 'amiabily': 0,\n",
              " 'amiable': 0,\n",
              " 'amicability': 0,\n",
              " 'amicable': 0,\n",
              " 'amicably': 0,\n",
              " 'amity': 0,\n",
              " 'ample': 0,\n",
              " 'amply': 0,\n",
              " 'amuse': 0,\n",
              " 'amusing': 0,\n",
              " 'amusingly': 0,\n",
              " 'angel': 0,\n",
              " 'angelic': 0,\n",
              " 'apotheosis': 0,\n",
              " 'appeal': 0,\n",
              " 'appealing': 0,\n",
              " 'applaud': 0,\n",
              " 'appreciable': 0,\n",
              " 'appreciate': 0,\n",
              " 'appreciated': 0,\n",
              " 'appreciates': 0,\n",
              " 'appreciative': 0,\n",
              " 'appreciatively': 0,\n",
              " 'appropriate': 0,\n",
              " 'approval': 0,\n",
              " 'approve': 0,\n",
              " 'ardent': 0,\n",
              " 'ardently': 0,\n",
              " 'ardor': 0,\n",
              " 'articulate': 0,\n",
              " 'aspiration': 0,\n",
              " 'aspirations': 0,\n",
              " 'aspire': 0,\n",
              " 'assurance': 0,\n",
              " 'assurances': 0,\n",
              " 'assure': 0,\n",
              " 'assuredly': 0,\n",
              " 'assuring': 0,\n",
              " 'astonish': 0,\n",
              " 'astonished': 0,\n",
              " 'astonishing': 0,\n",
              " 'astonishingly': 0,\n",
              " 'astonishment': 0,\n",
              " 'astound': 0,\n",
              " 'astounded': 0,\n",
              " 'astounding': 0,\n",
              " 'astoundingly': 0,\n",
              " 'astutely': 0,\n",
              " 'attentive': 0,\n",
              " 'attraction': 0,\n",
              " 'attractive': 0,\n",
              " 'attractively': 0,\n",
              " 'attune': 0,\n",
              " 'audible': 0,\n",
              " 'audibly': 0,\n",
              " 'auspicious': 0,\n",
              " 'authentic': 0,\n",
              " 'authoritative': 0,\n",
              " 'autonomous': 0,\n",
              " 'available': 0,\n",
              " 'aver': 0,\n",
              " 'avid': 0,\n",
              " 'avidly': 0,\n",
              " 'award': 0,\n",
              " 'awarded': 0,\n",
              " 'awards': 0,\n",
              " 'awe': 0,\n",
              " 'awed': 0,\n",
              " 'awesome': 0,\n",
              " 'awesomely': 0,\n",
              " 'awesomeness': 0,\n",
              " 'awestruck': 0,\n",
              " 'awsome': 0,\n",
              " 'backbone': 0,\n",
              " 'balanced': 0,\n",
              " 'bargain': 0,\n",
              " 'beauteous': 0,\n",
              " 'beautiful': 0,\n",
              " 'beautifullly': 0,\n",
              " 'beautifully': 0,\n",
              " 'beautify': 0,\n",
              " 'beauty': 0,\n",
              " 'beckon': 0,\n",
              " 'beckoned': 0,\n",
              " 'beckoning': 0,\n",
              " 'beckons': 0,\n",
              " 'believable': 0,\n",
              " 'believeable': 0,\n",
              " 'beloved': 0,\n",
              " 'benefactor': 0,\n",
              " 'beneficent': 0,\n",
              " 'beneficial': 0,\n",
              " 'beneficially': 0,\n",
              " 'beneficiary': 0,\n",
              " 'benefit': 0,\n",
              " 'benefits': 0,\n",
              " 'benevolence': 0,\n",
              " 'benevolent': 0,\n",
              " 'benifits': 0,\n",
              " 'best': 0,\n",
              " 'best-known': 0,\n",
              " 'best-performing': 0,\n",
              " 'best-selling': 0,\n",
              " 'better': 0,\n",
              " 'better-known': 0,\n",
              " 'better-than-expected': 0,\n",
              " 'beutifully': 0,\n",
              " 'blameless': 0,\n",
              " 'bless': 0,\n",
              " 'blessing': 0,\n",
              " 'bliss': 0,\n",
              " 'blissful': 0,\n",
              " 'blissfully': 0,\n",
              " 'blithe': 0,\n",
              " 'blockbuster': 0,\n",
              " 'bloom': 0,\n",
              " 'blossom': 0,\n",
              " 'bolster': 0,\n",
              " 'bonny': 0,\n",
              " 'bonus': 0,\n",
              " 'bonuses': 0,\n",
              " 'boom': 0,\n",
              " 'booming': 0,\n",
              " 'boost': 0,\n",
              " 'boundless': 0,\n",
              " 'bountiful': 0,\n",
              " 'brainiest': 0,\n",
              " 'brainy': 0,\n",
              " 'brand-new': 0,\n",
              " 'brave': 0,\n",
              " 'bravery': 0,\n",
              " 'bravo': 0,\n",
              " 'breakthrough': 0,\n",
              " 'breakthroughs': 0,\n",
              " 'breathlessness': 0,\n",
              " 'breathtaking': 0,\n",
              " 'breathtakingly': 0,\n",
              " 'breeze': 0,\n",
              " 'bright': 0,\n",
              " 'brighten': 0,\n",
              " 'brighter': 0,\n",
              " 'brightest': 0,\n",
              " 'brilliance': 0,\n",
              " 'brilliances': 0,\n",
              " 'brilliant': 0,\n",
              " 'brilliantly': 0,\n",
              " 'brisk': 0,\n",
              " 'brotherly': 0,\n",
              " 'bullish': 0,\n",
              " 'buoyant': 0,\n",
              " 'cajole': 0,\n",
              " 'calm': 0,\n",
              " 'calming': 0,\n",
              " 'calmness': 0,\n",
              " 'capability': 0,\n",
              " 'capable': 0,\n",
              " 'capably': 0,\n",
              " 'captivate': 0,\n",
              " 'captivating': 0,\n",
              " 'carefree': 0,\n",
              " 'cashback': 0,\n",
              " 'cashbacks': 0,\n",
              " 'catchy': 0,\n",
              " 'celebrate': 0,\n",
              " 'celebrated': 0,\n",
              " 'celebration': 0,\n",
              " 'celebratory': 0,\n",
              " 'champ': 0,\n",
              " 'champion': 0,\n",
              " 'charisma': 0,\n",
              " 'charismatic': 0,\n",
              " 'charitable': 0,\n",
              " 'charm': 0,\n",
              " 'charming': 0,\n",
              " 'charmingly': 0,\n",
              " 'chaste': 0,\n",
              " 'cheaper': 0,\n",
              " 'cheapest': 0,\n",
              " 'cheer': 0,\n",
              " 'cheerful': 0,\n",
              " 'cheery': 0,\n",
              " 'cherish': 0,\n",
              " 'cherished': 0,\n",
              " 'cherub': 0,\n",
              " 'chic': 0,\n",
              " 'chivalrous': 0,\n",
              " 'chivalry': 0,\n",
              " 'civility': 0,\n",
              " 'civilize': 0,\n",
              " 'clarity': 0,\n",
              " 'classic': 0,\n",
              " 'classy': 0,\n",
              " 'clean': 0,\n",
              " 'cleaner': 0,\n",
              " 'cleanest': 0,\n",
              " 'cleanliness': 0,\n",
              " 'cleanly': 0,\n",
              " 'clear': 0,\n",
              " 'clear-cut': 0,\n",
              " 'cleared': 0,\n",
              " 'clearer': 0,\n",
              " 'clearly': 0,\n",
              " 'clears': 0,\n",
              " 'clever': 0,\n",
              " 'cleverly': 0,\n",
              " 'cohere': 0,\n",
              " 'coherence': 0,\n",
              " 'coherent': 0,\n",
              " 'cohesive': 0,\n",
              " 'colorful': 0,\n",
              " 'comely': 0,\n",
              " 'comfort': 0,\n",
              " 'comfortable': 0,\n",
              " 'comfortably': 0,\n",
              " 'comforting': 0,\n",
              " 'comfy': 0,\n",
              " 'commend': 0,\n",
              " 'commendable': 0,\n",
              " 'commendably': 0,\n",
              " 'commitment': 0,\n",
              " 'commodious': 0,\n",
              " 'compact': 0,\n",
              " 'compactly': 0,\n",
              " 'compassion': 0,\n",
              " 'compassionate': 0,\n",
              " 'compatible': 0,\n",
              " 'competitive': 0,\n",
              " 'complement': 0,\n",
              " 'complementary': 0,\n",
              " 'complemented': 0,\n",
              " 'complements': 0,\n",
              " 'compliant': 0,\n",
              " 'compliment': 0,\n",
              " 'complimentary': 0,\n",
              " 'comprehensive': 0,\n",
              " 'conciliate': 0,\n",
              " 'conciliatory': 0,\n",
              " 'concise': 0,\n",
              " 'confidence': 0,\n",
              " 'confident': 0,\n",
              " 'congenial': 0,\n",
              " 'congratulate': 0,\n",
              " 'congratulation': 0,\n",
              " 'congratulations': 0,\n",
              " 'congratulatory': 0,\n",
              " 'conscientious': 0,\n",
              " 'considerate': 0,\n",
              " 'consistent': 0,\n",
              " 'consistently': 0,\n",
              " 'constructive': 0,\n",
              " 'consummate': 0,\n",
              " 'contentment': 0,\n",
              " 'continuity': 0,\n",
              " 'contrasty': 0,\n",
              " 'contribution': 0,\n",
              " 'convenience': 0,\n",
              " 'convenient': 0,\n",
              " 'conveniently': 0,\n",
              " 'convience': 0,\n",
              " 'convienient': 0,\n",
              " 'convient': 0,\n",
              " 'convincing': 0,\n",
              " 'convincingly': 0,\n",
              " 'cool': 0,\n",
              " 'coolest': 0,\n",
              " 'cooperative': 0,\n",
              " 'cooperatively': 0,\n",
              " 'cornerstone': 0,\n",
              " 'correct': 0,\n",
              " 'correctly': 0,\n",
              " 'cost-effective': 0,\n",
              " 'cost-saving': 0,\n",
              " 'counter-attack': 0,\n",
              " 'counter-attacks': 0,\n",
              " 'courage': 0,\n",
              " 'courageous': 0,\n",
              " 'courageously': 0,\n",
              " 'courageousness': 0,\n",
              " 'courteous': 0,\n",
              " 'courtly': 0,\n",
              " 'covenant': 0,\n",
              " 'cozy': 0,\n",
              " 'creative': 0,\n",
              " 'credence': 0,\n",
              " 'credible': 0,\n",
              " 'crisp': 0,\n",
              " 'crisper': 0,\n",
              " 'cure': 0,\n",
              " 'cure-all': 0,\n",
              " 'cushy': 0,\n",
              " 'cute': 0,\n",
              " 'cuteness': 0,\n",
              " 'danke': 0,\n",
              " 'danken': 0,\n",
              " 'daring': 0,\n",
              " 'daringly': 0,\n",
              " 'darling': 0,\n",
              " 'dashing': 0,\n",
              " 'dauntless': 0,\n",
              " 'dawn': 0,\n",
              " 'dazzle': 0,\n",
              " 'dazzled': 0,\n",
              " 'dazzling': 0,\n",
              " 'dead-cheap': 0,\n",
              " 'dead-on': 0,\n",
              " 'decency': 0,\n",
              " 'decent': 0,\n",
              " 'decisive': 0,\n",
              " 'decisiveness': 0,\n",
              " 'dedicated': 0,\n",
              " 'defeat': 0,\n",
              " 'defeated': 0,\n",
              " 'defeating': 0,\n",
              " 'defeats': 0,\n",
              " 'defender': 0,\n",
              " 'deference': 0,\n",
              " 'deft': 0,\n",
              " 'deginified': 0,\n",
              " 'delectable': 0,\n",
              " 'delicacy': 0,\n",
              " 'delicate': 0,\n",
              " 'delicious': 0,\n",
              " 'delight': 0,\n",
              " 'delighted': 0,\n",
              " 'delightful': 0,\n",
              " 'delightfully': 0,\n",
              " 'delightfulness': 0,\n",
              " 'dependable': 0,\n",
              " 'dependably': 0,\n",
              " 'deservedly': 0,\n",
              " 'deserving': 0,\n",
              " 'desirable': 0,\n",
              " 'desiring': 0,\n",
              " 'desirous': 0,\n",
              " 'destiny': 0,\n",
              " 'detachable': 0,\n",
              " 'devout': 0,\n",
              " 'dexterous': 0,\n",
              " 'dexterously': 0,\n",
              " 'dextrous': 0,\n",
              " 'dignified': 0,\n",
              " 'dignify': 0,\n",
              " 'dignity': 0,\n",
              " 'diligence': 0,\n",
              " 'diligent': 0,\n",
              " 'diligently': 0,\n",
              " 'diplomatic': 0,\n",
              " 'dirt-cheap': 0,\n",
              " 'distinction': 0,\n",
              " 'distinctive': 0,\n",
              " 'distinguished': 0,\n",
              " 'diversified': 0,\n",
              " 'divine': 0,\n",
              " 'divinely': 0,\n",
              " 'dominate': 0,\n",
              " 'dominated': 0,\n",
              " 'dominates': 0,\n",
              " 'dote': 0,\n",
              " 'dotingly': 0,\n",
              " 'doubtless': 0,\n",
              " 'dreamland': 0,\n",
              " 'dumbfounded': 0,\n",
              " 'dumbfounding': 0,\n",
              " 'dummy-proof': 0,\n",
              " 'durable': 0,\n",
              " 'dynamic': 0,\n",
              " 'eager': 0,\n",
              " 'eagerly': 0,\n",
              " 'eagerness': 0,\n",
              " 'earnest': 0,\n",
              " 'earnestly': 0,\n",
              " 'earnestness': 0,\n",
              " 'ease': 0,\n",
              " 'eased': 0,\n",
              " 'eases': 0,\n",
              " 'easier': 0,\n",
              " 'easiest': 0,\n",
              " 'easiness': 0,\n",
              " 'easing': 0,\n",
              " 'easy': 0,\n",
              " 'easy-to-use': 0,\n",
              " 'easygoing': 0,\n",
              " 'ebullience': 0,\n",
              " 'ebullient': 0,\n",
              " 'ebulliently': 0,\n",
              " 'ecenomical': 0,\n",
              " 'economical': 0,\n",
              " 'ecstasies': 0,\n",
              " 'ecstasy': 0,\n",
              " 'ecstatic': 0,\n",
              " 'ecstatically': 0,\n",
              " 'edify': 0,\n",
              " 'educated': 0,\n",
              " 'effective': 0,\n",
              " 'effectively': 0,\n",
              " 'effectiveness': 0,\n",
              " 'effectual': 0,\n",
              " 'efficacious': 0,\n",
              " 'efficient': 0,\n",
              " 'efficiently': 0,\n",
              " 'effortless': 0,\n",
              " 'effortlessly': 0,\n",
              " 'effusion': 0,\n",
              " 'effusive': 0,\n",
              " 'effusively': 0,\n",
              " 'effusiveness': 0,\n",
              " 'elan': 0,\n",
              " 'elate': 0,\n",
              " 'elated': 0,\n",
              " 'elatedly': 0,\n",
              " 'elation': 0,\n",
              " 'electrify': 0,\n",
              " 'elegance': 0,\n",
              " 'elegant': 0,\n",
              " 'elegantly': 0,\n",
              " 'elevate': 0,\n",
              " 'elite': 0,\n",
              " 'eloquence': 0,\n",
              " 'eloquent': 0,\n",
              " 'eloquently': 0,\n",
              " 'embolden': 0,\n",
              " 'eminence': 0,\n",
              " 'eminent': 0,\n",
              " 'empathize': 0,\n",
              " 'empathy': 0,\n",
              " 'empower': 0,\n",
              " 'empowerment': 0,\n",
              " 'enchant': 0,\n",
              " 'enchanted': 0,\n",
              " 'enchanting': 0,\n",
              " 'enchantingly': 0,\n",
              " 'encourage': 0,\n",
              " 'encouragement': 0,\n",
              " 'encouraging': 0,\n",
              " 'encouragingly': 0,\n",
              " 'endear': 0,\n",
              " 'endearing': 0,\n",
              " 'endorse': 0,\n",
              " 'endorsed': 0,\n",
              " 'endorsement': 0,\n",
              " 'endorses': 0,\n",
              " 'endorsing': 0,\n",
              " 'energetic': 0,\n",
              " 'energize': 0,\n",
              " 'energy-efficient': 0,\n",
              " 'energy-saving': 0,\n",
              " 'engaging': 0,\n",
              " 'engrossing': 0,\n",
              " 'enhance': 0,\n",
              " 'enhanced': 0,\n",
              " 'enhancement': 0,\n",
              " 'enhances': 0,\n",
              " 'enjoy': 0,\n",
              " 'enjoyable': 0,\n",
              " 'enjoyably': 0,\n",
              " 'enjoyed': 0,\n",
              " 'enjoying': 0,\n",
              " 'enjoyment': 0,\n",
              " 'enjoys': 0,\n",
              " 'enlighten': 0,\n",
              " 'enlightenment': 0,\n",
              " 'enliven': 0,\n",
              " 'ennoble': 0,\n",
              " 'enough': 0,\n",
              " 'enrapt': 0,\n",
              " 'enrapture': 0,\n",
              " 'enraptured': 0,\n",
              " 'enrich': 0,\n",
              " 'enrichment': 0,\n",
              " 'enterprising': 0,\n",
              " 'entertain': 0,\n",
              " 'entertaining': 0,\n",
              " 'entertains': 0,\n",
              " 'enthral': 0,\n",
              " 'enthrall': 0,\n",
              " 'enthralled': 0,\n",
              " 'enthuse': 0,\n",
              " 'enthusiasm': 0,\n",
              " 'enthusiast': 0,\n",
              " 'enthusiastic': 0,\n",
              " 'enthusiastically': 0,\n",
              " 'entice': 0,\n",
              " 'enticed': 0,\n",
              " 'enticing': 0,\n",
              " 'enticingly': 0,\n",
              " 'entranced': 0,\n",
              " 'entrancing': 0,\n",
              " 'entrust': 0,\n",
              " 'enviable': 0,\n",
              " 'enviably': 0,\n",
              " 'envious': 0,\n",
              " 'enviously': 0,\n",
              " 'enviousness': 0,\n",
              " 'envy': 0,\n",
              " 'equitable': 0,\n",
              " 'ergonomical': 0,\n",
              " 'err-free': 0,\n",
              " 'erudite': 0,\n",
              " 'ethical': 0,\n",
              " 'eulogize': 0,\n",
              " 'euphoria': 0,\n",
              " 'euphoric': 0,\n",
              " 'euphorically': 0,\n",
              " 'evaluative': 0,\n",
              " 'evenly': 0,\n",
              " 'eventful': 0,\n",
              " 'everlasting': 0,\n",
              " 'evocative': 0,\n",
              " 'exalt': 0,\n",
              " 'exaltation': 0,\n",
              " 'exalted': 0,\n",
              " 'exaltedly': 0,\n",
              " 'exalting': 0,\n",
              " 'exaltingly': 0,\n",
              " 'examplar': 0,\n",
              " 'examplary': 0,\n",
              " 'excallent': 0,\n",
              " 'exceed': 0,\n",
              " 'exceeded': 0,\n",
              " 'exceeding': 0,\n",
              " 'exceedingly': 0,\n",
              " 'exceeds': 0,\n",
              " 'excel': 0,\n",
              " 'exceled': 0,\n",
              " 'excelent': 0,\n",
              " 'excellant': 0,\n",
              " 'excelled': 0,\n",
              " 'excellence': 0,\n",
              " 'excellency': 0,\n",
              " 'excellent': 0,\n",
              " 'excellently': 0,\n",
              " 'excels': 0,\n",
              " 'exceptional': 0,\n",
              " 'exceptionally': 0,\n",
              " 'excite': 0,\n",
              " 'excited': 0,\n",
              " 'excitedly': 0,\n",
              " 'excitedness': 0,\n",
              " 'excitement': 0,\n",
              " 'excites': 0,\n",
              " 'exciting': 0,\n",
              " 'excitingly': 0,\n",
              " 'exellent': 0,\n",
              " 'exemplar': 0,\n",
              " 'exemplary': 0,\n",
              " 'exhilarate': 0,\n",
              " 'exhilarating': 0,\n",
              " 'exhilaratingly': 0,\n",
              " 'exhilaration': 0,\n",
              " 'exonerate': 0,\n",
              " 'expansive': 0,\n",
              " 'expeditiously': 0,\n",
              " 'expertly': 0,\n",
              " 'exquisite': 0,\n",
              " 'exquisitely': 0,\n",
              " 'extol': 0,\n",
              " 'extoll': 0,\n",
              " 'extraordinarily': 0,\n",
              " 'extraordinary': 0,\n",
              " 'exuberance': 0,\n",
              " 'exuberant': 0,\n",
              " 'exuberantly': 0,\n",
              " 'exult': 0,\n",
              " 'exultant': 0,\n",
              " 'exultation': 0,\n",
              " 'exultingly': 0,\n",
              " 'eye-catch': 0,\n",
              " 'eye-catching': 0,\n",
              " 'eyecatch': 0,\n",
              " 'eyecatching': 0,\n",
              " 'fabulous': 0,\n",
              " 'fabulously': 0,\n",
              " 'facilitate': 0,\n",
              " 'fair': 0,\n",
              " 'fairly': 0,\n",
              " 'fairness': 0,\n",
              " 'faith': 0,\n",
              " 'faithful': 0,\n",
              " 'faithfully': 0,\n",
              " 'faithfulness': 0,\n",
              " 'fame': 0,\n",
              " 'famed': 0,\n",
              " 'famous': 0,\n",
              " 'famously': 0,\n",
              " 'fancier': 0,\n",
              " 'fancinating': 0,\n",
              " 'fancy': 0,\n",
              " 'fanfare': 0,\n",
              " 'fans': 0,\n",
              " 'fantastic': 0,\n",
              " 'fantastically': 0,\n",
              " 'fascinate': 0,\n",
              " 'fascinating': 0,\n",
              " 'fascinatingly': 0,\n",
              " 'fascination': 0,\n",
              " 'fashionable': 0,\n",
              " 'fashionably': 0,\n",
              " 'fast': 0,\n",
              " 'fast-growing': 0,\n",
              " 'fast-paced': 0,\n",
              " 'faster': 0,\n",
              " 'fastest': 0,\n",
              " 'fastest-growing': 0,\n",
              " 'faultless': 0,\n",
              " 'fav': 0,\n",
              " 'fave': 0,\n",
              " 'favor': 0,\n",
              " 'favorable': 0,\n",
              " 'favored': 0,\n",
              " 'favorite': 0,\n",
              " 'favorited': 0,\n",
              " 'favour': 0,\n",
              " 'fearless': 0,\n",
              " 'fearlessly': 0,\n",
              " 'feasible': 0,\n",
              " 'feasibly': 0,\n",
              " 'feat': 0,\n",
              " 'feature-rich': 0,\n",
              " 'fecilitous': 0,\n",
              " 'feisty': 0,\n",
              " 'felicitate': 0,\n",
              " 'felicitous': 0,\n",
              " 'felicity': 0,\n",
              " 'fertile': 0,\n",
              " 'fervent': 0,\n",
              " 'fervently': 0,\n",
              " 'fervid': 0,\n",
              " 'fervidly': 0,\n",
              " 'fervor': 0,\n",
              " 'festive': 0,\n",
              " 'fidelity': 0,\n",
              " 'fiery': 0,\n",
              " 'fine': 0,\n",
              " 'fine-looking': 0,\n",
              " 'finely': 0,\n",
              " 'finer': 0,\n",
              " 'finest': 0,\n",
              " 'firmer': 0,\n",
              " 'first-class': 0,\n",
              " 'first-in-class': 0,\n",
              " 'first-rate': 0,\n",
              " 'flashy': 0,\n",
              " 'flatter': 0,\n",
              " 'flattering': 0,\n",
              " 'flatteringly': 0,\n",
              " 'flawless': 0,\n",
              " 'flawlessly': 0,\n",
              " 'flexibility': 0,\n",
              " 'flexible': 0,\n",
              " 'flourish': 0,\n",
              " 'flourishing': 0,\n",
              " 'fluent': 0,\n",
              " 'flutter': 0,\n",
              " 'fond': 0,\n",
              " 'fondly': 0,\n",
              " 'fondness': 0,\n",
              " 'foolproof': 0,\n",
              " 'foremost': 0,\n",
              " 'foresight': 0,\n",
              " 'formidable': 0,\n",
              " 'fortitude': 0,\n",
              " 'fortuitous': 0,\n",
              " 'fortuitously': 0,\n",
              " 'fortunate': 0,\n",
              " 'fortunately': 0,\n",
              " 'fortune': 0,\n",
              " 'fragrant': 0,\n",
              " 'free': 0,\n",
              " 'freed': 0,\n",
              " 'freedom': 0,\n",
              " 'freedoms': 0,\n",
              " 'fresh': 0,\n",
              " 'fresher': 0,\n",
              " 'freshest': 0,\n",
              " 'friendliness': 0,\n",
              " 'friendly': 0,\n",
              " 'frolic': 0,\n",
              " 'frugal': 0,\n",
              " 'fruitful': 0,\n",
              " 'ftw': 0,\n",
              " 'fulfillment': 0,\n",
              " 'fun': 0,\n",
              " 'futurestic': 0,\n",
              " 'futuristic': 0,\n",
              " 'gaiety': 0,\n",
              " 'gaily': 0,\n",
              " 'gain': 0,\n",
              " 'gained': 0,\n",
              " 'gainful': 0,\n",
              " 'gainfully': 0,\n",
              " 'gaining': 0,\n",
              " 'gains': 0,\n",
              " 'gallant': 0,\n",
              " 'gallantly': 0,\n",
              " 'galore': 0,\n",
              " 'geekier': 0,\n",
              " 'geeky': 0,\n",
              " 'gem': 0,\n",
              " 'gems': 0,\n",
              " 'generosity': 0,\n",
              " 'generous': 0,\n",
              " 'generously': 0,\n",
              " 'genial': 0,\n",
              " 'genius': 0,\n",
              " 'gentle': 0,\n",
              " 'gentlest': 0,\n",
              " 'genuine': 0,\n",
              " 'gifted': 0,\n",
              " 'glad': 0,\n",
              " 'gladden': 0,\n",
              " 'gladly': 0,\n",
              " 'gladness': 0,\n",
              " 'glamorous': 0,\n",
              " 'glee': 0,\n",
              " 'gleeful': 0,\n",
              " 'gleefully': 0,\n",
              " 'glimmer': 0,\n",
              " 'glimmering': 0,\n",
              " 'glisten': 0,\n",
              " 'glistening': 0,\n",
              " 'glitter': 0,\n",
              " 'glitz': 0,\n",
              " 'glorify': 0,\n",
              " 'glorious': 0,\n",
              " 'gloriously': 0,\n",
              " 'glory': 0,\n",
              " 'glow': 0,\n",
              " 'glowing': 0,\n",
              " 'glowingly': 0,\n",
              " 'god-given': 0,\n",
              " 'god-send': 0,\n",
              " 'godlike': 0,\n",
              " 'godsend': 0,\n",
              " 'gold': 0,\n",
              " 'golden': 0,\n",
              " 'good': 0,\n",
              " 'goodly': 0,\n",
              " 'goodness': 0,\n",
              " 'goodwill': 0,\n",
              " 'goood': 0,\n",
              " 'gooood': 0,\n",
              " 'gorgeous': 0,\n",
              " 'gorgeously': 0,\n",
              " 'grace': 0,\n",
              " 'graceful': 0,\n",
              " 'gracefully': 0,\n",
              " 'gracious': 0,\n",
              " 'graciously': 0,\n",
              " 'graciousness': 0,\n",
              " 'grand': 0,\n",
              " 'grandeur': 0,\n",
              " 'grateful': 0,\n",
              " 'gratefully': 0,\n",
              " 'gratification': 0,\n",
              " 'gratified': 0,\n",
              " 'gratifies': 0,\n",
              " 'gratify': 0,\n",
              " 'gratifying': 0,\n",
              " 'gratifyingly': 0,\n",
              " 'gratitude': 0,\n",
              " 'great': 0,\n",
              " 'greatest': 0,\n",
              " 'greatness': 0,\n",
              " 'grin': 0,\n",
              " 'groundbreaking': 0,\n",
              " 'guarantee': 0,\n",
              " 'guidance': 0,\n",
              " 'guiltless': 0,\n",
              " 'gumption': 0,\n",
              " 'gush': 0,\n",
              " 'gusto': 0,\n",
              " 'gutsy': 0,\n",
              " 'hail': 0,\n",
              " 'halcyon': 0,\n",
              " 'hale': 0,\n",
              " 'hallmark': 0,\n",
              " 'hallmarks': 0,\n",
              " 'hallowed': 0,\n",
              " 'handier': 0,\n",
              " 'handily': 0,\n",
              " 'hands-down': 0,\n",
              " 'handsome': 0,\n",
              " 'handsomely': 0,\n",
              " 'handy': 0,\n",
              " 'happier': 0,\n",
              " 'happily': 0,\n",
              " 'happiness': 0,\n",
              " 'happy': 0,\n",
              " 'hard-working': 0,\n",
              " 'hardier': 0,\n",
              " 'hardy': 0,\n",
              " 'harmless': 0,\n",
              " 'harmonious': 0,\n",
              " 'harmoniously': 0,\n",
              " 'harmonize': 0,\n",
              " 'harmony': 0,\n",
              " 'headway': 0,\n",
              " 'heal': 0,\n",
              " 'healthful': 0,\n",
              " 'healthy': 0,\n",
              " 'hearten': 0,\n",
              " 'heartening': 0,\n",
              " 'heartfelt': 0,\n",
              " 'heartily': 0,\n",
              " 'heartwarming': 0,\n",
              " 'heaven': 0,\n",
              " 'heavenly': 0,\n",
              " 'helped': 0,\n",
              " 'helpful': 0,\n",
              " 'helping': 0,\n",
              " 'hero': 0,\n",
              " 'heroic': 0,\n",
              " 'heroically': 0,\n",
              " 'heroine': 0,\n",
              " 'heroize': 0,\n",
              " 'heros': 0,\n",
              " 'high-quality': 0,\n",
              " 'high-spirited': 0,\n",
              " 'hilarious': 0,\n",
              " 'holy': 0,\n",
              " 'homage': 0,\n",
              " 'honest': 0,\n",
              " 'honesty': 0,\n",
              " 'honor': 0,\n",
              " 'honorable': 0,\n",
              " 'honored': 0,\n",
              " 'honoring': 0,\n",
              " 'hooray': 0,\n",
              " 'hopeful': 0,\n",
              " 'hospitable': 0,\n",
              " 'hot': 0,\n",
              " 'hotcake': 0,\n",
              " 'hotcakes': 0,\n",
              " 'hottest': 0,\n",
              " 'hug': 0,\n",
              " 'humane': 0,\n",
              " 'humble': 0,\n",
              " 'humility': 0,\n",
              " 'humor': 0,\n",
              " 'humorous': 0,\n",
              " 'humorously': 0,\n",
              " 'humour': 0,\n",
              " 'humourous': 0,\n",
              " 'ideal': 0,\n",
              " 'idealize': 0,\n",
              " 'ideally': 0,\n",
              " 'idol': 0,\n",
              " 'idolize': 0,\n",
              " 'idolized': 0,\n",
              " 'idyllic': 0,\n",
              " 'illuminate': 0,\n",
              " 'illuminati': 0,\n",
              " 'illuminating': 0,\n",
              " 'illumine': 0,\n",
              " 'illustrious': 0,\n",
              " 'ilu': 0,\n",
              " 'imaculate': 0,\n",
              " 'imaginative': 0,\n",
              " 'immaculate': 0,\n",
              " 'immaculately': 0,\n",
              " 'immense': 0,\n",
              " 'impartial': 0,\n",
              " 'impartiality': 0,\n",
              " 'impartially': 0,\n",
              " 'impassioned': 0,\n",
              " 'impeccable': 0,\n",
              " 'impeccably': 0,\n",
              " 'important': 0,\n",
              " 'impress': 0,\n",
              " 'impressed': 0,\n",
              " 'impresses': 0,\n",
              " 'impressive': 0,\n",
              " 'impressively': 0,\n",
              " 'impressiveness': 0,\n",
              " 'improve': 0,\n",
              " 'improved': 0,\n",
              " 'improvement': 0,\n",
              " 'improvements': 0,\n",
              " 'improves': 0,\n",
              " 'improving': 0,\n",
              " 'incredible': 0,\n",
              " 'incredibly': 0,\n",
              " 'indebted': 0,\n",
              " 'individualized': 0,\n",
              " 'indulgence': 0,\n",
              " 'indulgent': 0,\n",
              " 'industrious': 0,\n",
              " 'inestimable': 0,\n",
              " 'inestimably': 0,\n",
              " 'inexpensive': 0,\n",
              " 'infallibility': 0,\n",
              " 'infallible': 0,\n",
              " 'infallibly': 0,\n",
              " 'influential': 0,\n",
              " 'ingenious': 0,\n",
              " 'ingeniously': 0,\n",
              " 'ingenuity': 0,\n",
              " 'ingenuous': 0,\n",
              " 'ingenuously': 0,\n",
              " 'innocuous': 0,\n",
              " 'innovation': 0,\n",
              " 'innovative': 0,\n",
              " 'inpressed': 0,\n",
              " 'insightful': 0,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "positive_words_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "podsT4R9DXVA",
        "outputId": "0aeb7246-efdb-4e25-be7b-0369f5f64f14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "positive_words_dict['abound']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_KIPJjC-ZfX"
      },
      "outputs": [],
      "source": [
        "# Calculating how many times the positive_words & negative_words token appeared in the text_content\n",
        "for token in text_content_tokens:\n",
        "\n",
        "  if token in positive_words :\n",
        "    positive_words_dict[token] = positive_words_dict[token] + 1\n",
        "\n",
        "  if token in negative_words :\n",
        "    negative_words_dict[token] = negative_words_dict[token] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugm_8mYwB3Y8"
      },
      "outputs": [],
      "source": [
        "# Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Score\n",
        "\n",
        "positive_score = sum(positive_words_dict.values())\n",
        "\n",
        "negative_score = sum(negative_words_dict.values())\n",
        "\n",
        "polarity_score = ( positive_score - negative_score )/ (( positive_score + negative_score) + 0.000001)\n",
        "\n",
        "subjectivity_score = (positive_score + negative_score)/ (( len(text_content_tokens) ) + 0.000001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUrt_L9sELQy",
        "outputId": "c1aa9df7-5727-4020-a950-925c89150ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "6\n",
            "0.6249999804687506\n",
            "0.07002188168485365\n"
          ]
        }
      ],
      "source": [
        "print(positive_score)\n",
        "print(negative_score)\n",
        "print(polarity_score)\n",
        "print(subjectivity_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for popositive_negative_polarity_subjectivity_score\n",
        "def positive_negative_polarity_subjectivity_score(text_content_tokens):\n",
        "\n",
        "  # Creating a Positive_words_dict & Negative_words_dict\n",
        "\n",
        "  positive_words_dict = {}\n",
        "  negative_words_dict = {}\n",
        "\n",
        "  for word in positive_words:\n",
        "    positive_words_dict[word] = 0\n",
        "\n",
        "  for word in negative_words:\n",
        "    negative_words_dict[word] = 0\n",
        "\n",
        "  # Calculating how many times the positive_words & negative_words token appeared in the text_content\n",
        "  for token in text_content_tokens:\n",
        "\n",
        "    if token in positive_words :\n",
        "      positive_words_dict[token] = positive_words_dict[token] + 1\n",
        "\n",
        "    if token in negative_words :\n",
        "      negative_words_dict[token] = negative_words_dict[token] + 1\n",
        "\n",
        "  # Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Score\n",
        "\n",
        "  positive_score = sum(positive_words_dict.values())\n",
        "  negative_score = sum(negative_words_dict.values())\n",
        "\n",
        "  polarity_score = ( positive_score - negative_score )/ (( positive_score + negative_score) + 0.000001)\n",
        "  subjectivity_score = (positive_score + negative_score)/ (( len(text_content_tokens) ) + 0.000001)\n",
        "\n",
        "  return positive_score, negative_score, polarity_score, subjectivity_score"
      ],
      "metadata": {
        "id": "QGVg6OPr8Y0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "positive_score, negative_score, polarity_score, subjectivity_score = positive_negative_polarity_subjectivity_score(text_content_tokens)\n",
        "print(positive_score)\n",
        "print(negative_score)\n",
        "print(polarity_score)\n",
        "print(subjectivity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO6DXSbP9Ikz",
        "outputId": "f1300b85-66ea-4d84-fa38-2333d8ffaade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "6\n",
            "0.6249999804687506\n",
            "0.07002188168485365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoCCRiazHgx_"
      },
      "source": [
        "#### 2. Analysis of Readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIKYkK9PLSmO"
      },
      "outputs": [],
      "source": [
        "# Code for Extracting the complex words present in the text\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "\n",
        "def is_complex_word(word):\n",
        "    synsets = wn.synsets(word)\n",
        "    return len(synsets) > 1  # Check if word has multiple synsets (multiple morphemes)\n",
        "\n",
        "def extract_complex_words(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    complex_words = [word for word in tokens if is_complex_word(word)]\n",
        "    return complex_words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zajMcEd9NqVD"
      },
      "outputs": [],
      "source": [
        "# # Code for Extracting the complex words present in the text\n",
        "\n",
        "# import nltk\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.corpus import cmudict\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('cmudict')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "# def count_syllables(word):\n",
        "#     \"\"\"Count syllables in a word using the CMU Pronouncing Dictionary.\"\"\"\n",
        "#     if word.lower() in cmudict.dict():\n",
        "#         return max([len(list(y for y in x if y[-1].isdigit())) for x in cmudict.dict()[word.lower()]])\n",
        "#     else:\n",
        "#         return 0\n",
        "\n",
        "# def extract_complex_words(text):\n",
        "#     \"\"\"Extract complex words from the text based on more than two syllables.\"\"\"\n",
        "#     tokens = word_tokenize(text)\n",
        "#     complex_words = [word for word in tokens if count_syllables(word) >= 2]\n",
        "#     return complex_words\n",
        "\n",
        "\n",
        "# text = \"Complex words typically have more than two syllables, such as 'complexity', 'syllables', and 'typical'.\"\n",
        "# complex_words = extract_complex_words(text)\n",
        "# print(\"Complex words extracted from the text:\")\n",
        "# print(complex_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dt1SphmHjMp"
      },
      "outputs": [],
      "source": [
        "# Analysis of Readability is calculated using the Gunning Fox index formula described below.\n",
        "\n",
        "the_number_of_words     = len( raw_text_content.split())\n",
        "the_number_of_sentences = len( raw_text_content.split('.'))\n",
        "avg_sentence_length     = the_number_of_words / the_number_of_sentences\n",
        "\n",
        "# Extracting Complex words and its count\n",
        "complex_words               = extract_complex_words(raw_text_content)\n",
        "the_number_of_complex_words = len(complex_words)\n",
        "percentage_of_complex_words = the_number_of_complex_words / the_number_of_words\n",
        "\n",
        "\n",
        "fog_index = 0.4 * ( avg_sentence_length + percentage_of_complex_words )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvYZ99k-NXCt"
      },
      "source": [
        "#### 3. Average Number of Words Per Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhpBC5ZXNTaK"
      },
      "outputs": [],
      "source": [
        "avg_number_of_words_per_sentence = the_number_of_words / the_number_of_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTcYhfRwNqac",
        "outputId": "ca382300-f0c5-410e-b990-2705b135e398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.4875"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "avg_number_of_words_per_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45z-IXa_OA01"
      },
      "source": [
        "#### 4. Complex Word Count\n",
        "Complex words are words in the text that contain more than two syllables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poMANAHwQUiJ"
      },
      "outputs": [],
      "source": [
        "the_number_of_complex_words = len(complex_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **I have   taken the complex number count which calculated while calculating percentage_of_complex_words.**"
      ],
      "metadata": {
        "id": "jFF4GHkTonZd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7QG0uZBQVTS"
      },
      "source": [
        "#### 5. Word Count\n",
        "We count the total cleaned words present in the text by\n",
        "- removing the stop words (using stopwords class of nltk package).\n",
        "\n",
        "- removing any punctuations like ? ! , . from the word before counting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e47Jg0sPQv48"
      },
      "outputs": [],
      "source": [
        "# text_content contain text after removing the punctuation and stopwords given in stopwords lists\n",
        "word_count = len(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Syllable Count Per Word\n",
        "\n",
        "We count the number of Syllables in each word of the text by counting the vowels present in each word. We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable."
      ],
      "metadata": {
        "id": "cSjjEPtJqzgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Syllable Count Per Word\n",
        "\n",
        "def count_syllables(word):\n",
        "    word = word.lower()\n",
        "\n",
        "    # Handle special cases\n",
        "    if len(word) <= 3:\n",
        "        return 1\n",
        "    if word.endswith('es') or word.endswith('ed'):\n",
        "        if len(re.findall(r'[aeiouy]', word)) == 1:\n",
        "            return 1\n",
        "\n",
        "    # Count vowel groups\n",
        "    syllable_count = len(re.findall(r'[aeiouy]+', word))\n",
        "\n",
        "    # Adjust for silent 'e' at the end\n",
        "    if word.endswith('e'):\n",
        "        syllable_count -= 1\n",
        "\n",
        "    # Ensure at least one syllable\n",
        "    return max(1, syllable_count)\n",
        "\n",
        "def count_syllables_per_word(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    syllables_count = {}\n",
        "    for word in tokens:\n",
        "        syllables_count[word] = count_syllables(word)\n",
        "    return syllables_count"
      ],
      "metadata": {
        "id": "3PJSyJipsVpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Processed text_content is passed to reduced\n",
        "syllables_count = count_syllables_per_word(raw_text_content)\n",
        "\n",
        "\n",
        "# Here I have taken average syllables count per word in the text\n",
        "syllables_count_per_word = sum(syllables_count.values()) / len(syllables_count)"
      ],
      "metadata": {
        "id": "_xYt8CGbsgGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syllables_count_per_word           # Each word conatin almost 2 syllables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1OjUdCv5BU",
        "outputId": "a367aa98-61a7-4084-b49d-b62fc9c1fb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8721227621483376"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Personal Pronouns\n",
        "To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken so that the country name US is not included in the list."
      ],
      "metadata": {
        "id": "asR-end7wBbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # count_personal_pronouns function is created to calculate the number of pronouns present in the text\n",
        "\n",
        "def count_personal_pronouns(text):\n",
        "    # Define the personal pronouns to count\n",
        "    personal_pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Initialize the count dictionary\n",
        "    pronoun_count = {pronoun: 0 for pronoun in personal_pronouns}\n",
        "\n",
        "    # Compile regex patterns for personal pronouns\n",
        "    pronoun_patterns = {pronoun: re.compile(r'\\b' + pronoun + r'\\b', re.IGNORECASE) for pronoun in personal_pronouns}\n",
        "\n",
        "    # Iterate over tokens and count personal pronouns, excluding 'US'\n",
        "    for token in tokens:\n",
        "        if token.lower() != 'us':  # Exclude the country name 'US'\n",
        "            for pronoun, pattern in pronoun_patterns.items():\n",
        "                if pattern.match(token):\n",
        "                    pronoun_count[pronoun] += 1\n",
        "\n",
        "    return pronoun_count\n"
      ],
      "metadata": {
        "id": "jNMRfdARwa4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiLDVsOEKBc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e448f8-1752-4c6f-f1d3-217a956efb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "personal_pronoun        = count_personal_pronouns(raw_text_content)\n",
        "personal_pronoun_counts = sum(personal_pronoun.values())\n",
        "print(personal_pronoun_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Average Word Length\n",
        "Average Word Length is calculated by the formula:\n",
        "\n",
        "Sum of the total number of characters in each word/Total number of words"
      ],
      "metadata": {
        "id": "4OtAYohRyT3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average_word_length\n",
        "\n",
        "def average_word_length(text):\n",
        "    # Tokenize the text into words\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation and other non-word tokens\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Calculate the sum of the total number of characters in each word\n",
        "    total_characters = sum(len(word) for word in words)\n",
        "\n",
        "    # Calculate the total number of words\n",
        "    total_words = len(words)\n",
        "\n",
        "    # Calculate the average word length\n",
        "    average_length = total_characters / total_words if total_words > 0 else 0\n",
        "\n",
        "    return average_length"
      ],
      "metadata": {
        "id": "PykMRiGhzLs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_word_length = round( average_word_length(raw_text_content) ,2)"
      ],
      "metadata": {
        "id": "cDt1vMnNzYuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_word_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxqmfAOczv-C",
        "outputId": "8b4f10df-6aa1-4d37-ad15-dfdaef612732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Function"
      ],
      "metadata": {
        "id": "MtuKtKevFRL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop for reading and extracting all the scores for 100 text files\n",
        "\n",
        "file_names_list  = input['URL_ID']\n",
        "url_list         = input['URL']\n",
        "\n",
        "# 1. Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Score\n",
        "positive_score_list = []\n",
        "negative_score_list = []\n",
        "polarity_score_list = []\n",
        "subjectivity_score_list = []\n",
        "\n",
        "# 2. Analysis of Readability\n",
        "avg_sentence_length_score_list= []\n",
        "percentage_of_complex_words_list = []\n",
        "fog_index_list = []\n",
        "\n",
        "# 3. Average Number of Words Per Sentence\n",
        "avg_number_of_words_per_sentence_list = []\n",
        "\n",
        "# 4. Complex Word Count\n",
        "the_number_of_complex_words_list = []\n",
        "\n",
        "# 5. Word Count\n",
        "word_count_list = []\n",
        "\n",
        "# 6. Syllable Count Per Word\n",
        "syllables_count_per_word_list = []\n",
        "\n",
        "# 7. Personal Pronouns\n",
        "personal_pronoun_counts_list = []\n",
        "\n",
        "# 8. Average Word Length\n",
        "avg_word_length_list = []\n"
      ],
      "metadata": {
        "id": "lmznNGPrF3do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the program for all 100 text files\n",
        "count = 1\n",
        "for file_name in file_names_list:\n",
        "\n",
        "  # Reading the text file                                      # file_path = \"blackassign0001.txt\"\n",
        "  raw_text_content  = read_text_file( f'{file_name}.txt' )\n",
        "\n",
        "  # applying the function for lowercaseing and to remove the punctuation\n",
        "  text_content = lowercasing_and_remove_punctuation( raw_text_content)\n",
        "\n",
        "  # applying the function to remove the punctuation\n",
        "  text_content = remove_url_and_digits( text_content)\n",
        "\n",
        "  # Applying remove_stopword function to remove stopwords from the text_content\n",
        "  text_content = remove_stopwords(text_content)\n",
        "\n",
        "  # text_tokenization for tokenizing the words in text_content\n",
        "  text_content_tokens = text_tokenization(text_content)\n",
        "\n",
        "\n",
        "# 1 -----------------------------------------------------------------------------------------------------------------------\n",
        "  # Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Scor\n",
        "  positive_score, negative_score, polarity_score, subjectivity_score = positive_negative_polarity_subjectivity_score(text_content_tokens)\n",
        "\n",
        "  positive_score_list.append( positive_score )\n",
        "  negative_score_list.append( negative_score )\n",
        "  polarity_score_list.append( polarity_score )\n",
        "  subjectivity_score_list.append( subjectivity_score )\n",
        "\n",
        "\n",
        "# 2 -----------------------------------------------------------------------------------------------------------------------\n",
        "  # Analysis of Readability is calculated using the Gunning Fox index formula described below.\n",
        "  the_number_of_words     = len( raw_text_content.split())\n",
        "  the_number_of_sentences = len( raw_text_content.split('.'))\n",
        "  avg_sentence_length     = the_number_of_words / the_number_of_sentences\n",
        "\n",
        "  # Extracting Complex words and its count\n",
        "  complex_words               = extract_complex_words(raw_text_content)\n",
        "  the_number_of_complex_words = len(complex_words)\n",
        "  percentage_of_complex_words = the_number_of_complex_words / the_number_of_words\n",
        "\n",
        "  fog_index = 0.4 * ( avg_sentence_length + percentage_of_complex_words )\n",
        "\n",
        "  avg_sentence_length_score_list.append( avg_sentence_length )\n",
        "  percentage_of_complex_words_list.append( percentage_of_complex_words )\n",
        "  fog_index_list.append( fog_index )\n",
        "\n",
        "# 3 -----------------------------------------------------------------------------------------------------------------------\n",
        "  avg_number_of_words_per_sentence = the_number_of_words / the_number_of_sentences\n",
        "  avg_number_of_words_per_sentence_list.append( avg_number_of_words_per_sentence )\n",
        "\n",
        "# 4 -----------------------------------------------------------------------------------------------------------------------\n",
        "  the_number_of_complex_words = len(complex_words)\n",
        "  the_number_of_complex_words_list.append( the_number_of_complex_words )\n",
        "\n",
        "# 5 -----------------------------------------------------------------------------------------------------------------------\n",
        "  # text_content contain text after removing the punctuation and stopwords given in stopwords lists\n",
        "  word_count = len(text_content)\n",
        "  word_count_list.append( word_count )\n",
        "\n",
        "# 6 -----------------------------------------------------------------------------------------------------------------------\n",
        "  #  syllables_count is calculated from the raw_text_content\n",
        "  syllables_count = count_syllables_per_word(raw_text_content)\n",
        "\n",
        "  # Here I have taken average syllables count per word in the text\n",
        "  syllables_count_per_word = sum(syllables_count.values()) / len(syllables_count)\n",
        "\n",
        "  syllables_count_per_word_list.append( syllables_count_per_word )\n",
        "\n",
        "# 7 -----------------------------------------------------------------------------------------------------------------------\n",
        "  # count_personal_pronouns function is created to calculate the number of pronouns present in the text\n",
        "  personal_pronoun        = count_personal_pronouns(raw_text_content)\n",
        "  personal_pronoun_counts = sum(personal_pronoun.values())\n",
        "  personal_pronoun_counts_list.append( personal_pronoun_counts )\n",
        "\n",
        "# 8 -----------------------------------------------------------------------------------------------------------------------\n",
        "  # average_word_length function is used to calculate Sum of the total number of characters in each word/Total number of words\n",
        "  avg_word_length = round( average_word_length(raw_text_content) ,2)\n",
        "  avg_word_length_list.append( avg_word_length )\n",
        "\n",
        "  print(count)\n",
        "  count +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P2BVink2oEM",
        "outputId": "e61bb93a-fe91-4ffb-bd6b-281e0dcca812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully read with encoding utf-8:\n",
            "1\n",
            "File successfully read with encoding utf-8:\n",
            "2\n",
            "File successfully read with encoding utf-8:\n",
            "3\n",
            "File successfully read with encoding utf-8:\n",
            "4\n",
            "File successfully read with encoding utf-8:\n",
            "5\n",
            "File successfully read with encoding utf-8:\n",
            "6\n",
            "File successfully read with encoding utf-8:\n",
            "7\n",
            "File successfully read with encoding utf-8:\n",
            "8\n",
            "File successfully read with encoding utf-8:\n",
            "9\n",
            "File successfully read with encoding utf-8:\n",
            "10\n",
            "File successfully read with encoding utf-8:\n",
            "11\n",
            "File successfully read with encoding utf-8:\n",
            "12\n",
            "File successfully read with encoding utf-8:\n",
            "13\n",
            "File successfully read with encoding utf-8:\n",
            "14\n",
            "File successfully read with encoding utf-8:\n",
            "15\n",
            "File successfully read with encoding utf-8:\n",
            "16\n",
            "File successfully read with encoding utf-8:\n",
            "17\n",
            "File successfully read with encoding utf-8:\n",
            "18\n",
            "File successfully read with encoding utf-8:\n",
            "19\n",
            "File successfully read with encoding utf-8:\n",
            "20\n",
            "File successfully read with encoding utf-8:\n",
            "21\n",
            "File successfully read with encoding utf-8:\n",
            "22\n",
            "File successfully read with encoding utf-8:\n",
            "23\n",
            "File successfully read with encoding utf-8:\n",
            "24\n",
            "File successfully read with encoding utf-8:\n",
            "25\n",
            "File successfully read with encoding utf-8:\n",
            "26\n",
            "File successfully read with encoding utf-8:\n",
            "27\n",
            "File successfully read with encoding utf-8:\n",
            "28\n",
            "File successfully read with encoding utf-8:\n",
            "29\n",
            "File successfully read with encoding utf-8:\n",
            "30\n",
            "File successfully read with encoding utf-8:\n",
            "31\n",
            "File successfully read with encoding utf-8:\n",
            "32\n",
            "File successfully read with encoding utf-8:\n",
            "33\n",
            "File successfully read with encoding utf-8:\n",
            "34\n",
            "File successfully read with encoding utf-8:\n",
            "35\n",
            "File successfully read with encoding utf-8:\n",
            "36\n",
            "File successfully read with encoding utf-8:\n",
            "37\n",
            "File successfully read with encoding utf-8:\n",
            "38\n",
            "File successfully read with encoding utf-8:\n",
            "39\n",
            "File successfully read with encoding utf-8:\n",
            "40\n",
            "File successfully read with encoding utf-8:\n",
            "41\n",
            "File successfully read with encoding utf-8:\n",
            "42\n",
            "File successfully read with encoding utf-8:\n",
            "43\n",
            "File successfully read with encoding utf-8:\n",
            "44\n",
            "File successfully read with encoding utf-8:\n",
            "45\n",
            "File successfully read with encoding utf-8:\n",
            "46\n",
            "File successfully read with encoding utf-8:\n",
            "47\n",
            "File successfully read with encoding utf-8:\n",
            "48\n",
            "File successfully read with encoding utf-8:\n",
            "49\n",
            "File successfully read with encoding utf-8:\n",
            "50\n",
            "File successfully read with encoding utf-8:\n",
            "51\n",
            "File successfully read with encoding utf-8:\n",
            "52\n",
            "File successfully read with encoding utf-8:\n",
            "53\n",
            "File successfully read with encoding utf-8:\n",
            "54\n",
            "File successfully read with encoding utf-8:\n",
            "55\n",
            "File successfully read with encoding utf-8:\n",
            "56\n",
            "File successfully read with encoding utf-8:\n",
            "57\n",
            "File successfully read with encoding utf-8:\n",
            "58\n",
            "File successfully read with encoding utf-8:\n",
            "59\n",
            "File successfully read with encoding utf-8:\n",
            "60\n",
            "File successfully read with encoding utf-8:\n",
            "61\n",
            "File successfully read with encoding utf-8:\n",
            "62\n",
            "File successfully read with encoding utf-8:\n",
            "63\n",
            "File successfully read with encoding utf-8:\n",
            "64\n",
            "File successfully read with encoding utf-8:\n",
            "65\n",
            "File successfully read with encoding utf-8:\n",
            "66\n",
            "File successfully read with encoding utf-8:\n",
            "67\n",
            "File successfully read with encoding utf-8:\n",
            "68\n",
            "File successfully read with encoding utf-8:\n",
            "69\n",
            "File successfully read with encoding utf-8:\n",
            "70\n",
            "File successfully read with encoding utf-8:\n",
            "71\n",
            "File successfully read with encoding utf-8:\n",
            "72\n",
            "File successfully read with encoding utf-8:\n",
            "73\n",
            "File successfully read with encoding utf-8:\n",
            "74\n",
            "File successfully read with encoding utf-8:\n",
            "75\n",
            "File successfully read with encoding utf-8:\n",
            "76\n",
            "File successfully read with encoding utf-8:\n",
            "77\n",
            "File successfully read with encoding utf-8:\n",
            "78\n",
            "File successfully read with encoding utf-8:\n",
            "79\n",
            "File successfully read with encoding utf-8:\n",
            "80\n",
            "File successfully read with encoding utf-8:\n",
            "81\n",
            "File successfully read with encoding utf-8:\n",
            "82\n",
            "File successfully read with encoding utf-8:\n",
            "83\n",
            "File successfully read with encoding utf-8:\n",
            "84\n",
            "File successfully read with encoding utf-8:\n",
            "85\n",
            "File successfully read with encoding utf-8:\n",
            "86\n",
            "File successfully read with encoding utf-8:\n",
            "87\n",
            "File successfully read with encoding utf-8:\n",
            "88\n",
            "File successfully read with encoding utf-8:\n",
            "89\n",
            "File successfully read with encoding utf-8:\n",
            "90\n",
            "File successfully read with encoding utf-8:\n",
            "91\n",
            "File successfully read with encoding utf-8:\n",
            "92\n",
            "File successfully read with encoding utf-8:\n",
            "93\n",
            "File successfully read with encoding utf-8:\n",
            "94\n",
            "File successfully read with encoding utf-8:\n",
            "95\n",
            "File successfully read with encoding utf-8:\n",
            "96\n",
            "File successfully read with encoding utf-8:\n",
            "97\n",
            "File successfully read with encoding utf-8:\n",
            "98\n",
            "File successfully read with encoding utf-8:\n",
            "99\n",
            "File successfully read with encoding utf-8:\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loop for reading and extracting all the scores for 100 text files\n",
        "\n",
        "# file_names_list  = input['URL_ID']\n",
        "# url_list         = input['URL']\n",
        "\n",
        "# # 1. Calculating the Positive score, Negative Score, Polarity Score & Subjectivity Score\n",
        "# positive_score_list = []\n",
        "# negative_score_list = []\n",
        "# polarity_score_list = []\n",
        "# subjectivity_score_list = []\n",
        "\n",
        "# # 2. Analysis of Readability\n",
        "# avg_sentence_length_score_list= []\n",
        "# percentage_of_complex_words_list = []\n",
        "# fog_index_list = []\n",
        "\n",
        "# # 3. Average Number of Words Per Sentence\n",
        "# avg_number_of_words_per_sentence_list = []\n",
        "\n",
        "# # 4. Complex Word Count\n",
        "# the_number_of_complex_words_list = []\n",
        "\n",
        "# # 5. Word Count\n",
        "# word_count_list = []\n",
        "\n",
        "# # 6. Syllable Count Per Word\n",
        "# syllables_count_per_word_list = []\n",
        "\n",
        "# # 7. Personal Pronouns\n",
        "# personal_pronoun_counts_list = []\n",
        "\n",
        "# # 8. Average Word Length\n",
        "# avg_word_length_list = []\n"
      ],
      "metadata": {
        "id": "rZLagHtPzw8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(positive_score_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_FL5ImnHg2l",
        "outputId": "f72bd27f-7c0e-483e-83bb-cca97da5d272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame\n",
        "Output_file = pd.DataFrame({\n",
        "                      'URL_ID'               : file_names_list,\n",
        "                      'URL'                  : url_list,\n",
        "                      'POSITIVE SCORE'       : positive_score_list,\n",
        "                      'NEGATIVE SCORE'       : negative_score_list,\n",
        "                      'POLARITY SCORE'       : polarity_score_list,\n",
        "                      'SUBJECTIVITY SCORE'   : subjectivity_score_list,\n",
        "                      'AVG SENTENCE LENGTH'  : avg_sentence_length_score_list,\n",
        "                      'PERCENTAGE OF COMPLEX WORDS' : percentage_of_complex_words_list,\n",
        "                      'FOG INDEX'            : fog_index_list,\n",
        "                      'AVG NUMBER OF WORDS PER SENTENCE' : avg_number_of_words_per_sentence_list,\n",
        "                      'COMPLEX WORD COUNT'   : the_number_of_complex_words_list,\n",
        "                      'WORD COUNT'           : word_count_list,\n",
        "                      'SYLLABLE PER WORD'    : syllables_count_per_word_list,\n",
        "                      'PERSONAL PRONOUNS'    : personal_pronoun_counts_list,\n",
        "                      'AVG WORD LENGTH'      : avg_word_length_list\n",
        "})"
      ],
      "metadata": {
        "id": "sqhMnA00Hi6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Output_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "NIFM5bHOK65U",
        "outputId": "36139bef-f023-427d-c7db-89e1941a0927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             URL_ID                                                URL  \\\n",
              "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
              "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
              "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
              "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
              "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
              "..              ...                                                ...   \n",
              "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
              "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
              "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
              "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
              "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
              "\n",
              "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
              "0               26               6        0.625000            0.070022   \n",
              "1               51              31        0.243902            0.127925   \n",
              "2               36              23        0.220339            0.097844   \n",
              "3               36              74       -0.345455            0.191304   \n",
              "4               19               8        0.407407            0.080838   \n",
              "..             ...             ...             ...                 ...   \n",
              "95              24              54       -0.384615            0.151751   \n",
              "96              21              35       -0.250000            0.144703   \n",
              "97               5               3        0.250000            0.041237   \n",
              "98              11               3        0.571429            0.056911   \n",
              "99              31              57       -0.295455            0.186441   \n",
              "\n",
              "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
              "0             15.487500                     0.640839   6.451336   \n",
              "1             18.012195                     0.683142   7.478135   \n",
              "2             18.859649                     0.625116   7.793906   \n",
              "3             20.442308                     0.650988   8.437318   \n",
              "4             16.878049                     0.608382   6.994572   \n",
              "..                  ...                          ...        ...   \n",
              "95            21.264151                     0.643301   8.762981   \n",
              "96            27.175000                     0.601656  11.110662   \n",
              "97            15.800000                     0.655696   6.582278   \n",
              "98            17.657143                     0.661812   7.327582   \n",
              "99            29.828571                     0.639847  12.187367   \n",
              "\n",
              "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
              "0                          15.487500                 794        3639   \n",
              "1                          18.012195                1009        5749   \n",
              "2                          18.859649                 672        5693   \n",
              "3                          20.442308                 692        5317   \n",
              "4                          16.878049                 421        3007   \n",
              "..                               ...                 ...         ...   \n",
              "95                         21.264151                 725        4382   \n",
              "96                         27.175000                 654        3081   \n",
              "97                         15.800000                 259        1682   \n",
              "98                         17.657143                 409        1889   \n",
              "99                         29.828571                 668        4032   \n",
              "\n",
              "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
              "0            1.872123                 11             4.60  \n",
              "1            2.251121                  3             5.40  \n",
              "2            2.439294                 12             6.06  \n",
              "3            2.423150                  5             5.93  \n",
              "4            2.140110                  6             5.41  \n",
              "..                ...                ...              ...  \n",
              "95           2.173507                  3             5.19  \n",
              "96           1.848780                  6             4.66  \n",
              "97           2.126582                  0             5.42  \n",
              "98           1.733533                  4             4.71  \n",
              "99           2.089253                  3             5.18  \n",
              "\n",
              "[100 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-602d11ae-5425-4046-8780-64a4724355f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "      <th>POSITIVE SCORE</th>\n",
              "      <th>NEGATIVE SCORE</th>\n",
              "      <th>POLARITY SCORE</th>\n",
              "      <th>SUBJECTIVITY SCORE</th>\n",
              "      <th>AVG SENTENCE LENGTH</th>\n",
              "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
              "      <th>FOG INDEX</th>\n",
              "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
              "      <th>COMPLEX WORD COUNT</th>\n",
              "      <th>WORD COUNT</th>\n",
              "      <th>SYLLABLE PER WORD</th>\n",
              "      <th>PERSONAL PRONOUNS</th>\n",
              "      <th>AVG WORD LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blackassign0001</td>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.070022</td>\n",
              "      <td>15.487500</td>\n",
              "      <td>0.640839</td>\n",
              "      <td>6.451336</td>\n",
              "      <td>15.487500</td>\n",
              "      <td>794</td>\n",
              "      <td>3639</td>\n",
              "      <td>1.872123</td>\n",
              "      <td>11</td>\n",
              "      <td>4.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blackassign0002</td>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "      <td>51</td>\n",
              "      <td>31</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.127925</td>\n",
              "      <td>18.012195</td>\n",
              "      <td>0.683142</td>\n",
              "      <td>7.478135</td>\n",
              "      <td>18.012195</td>\n",
              "      <td>1009</td>\n",
              "      <td>5749</td>\n",
              "      <td>2.251121</td>\n",
              "      <td>3</td>\n",
              "      <td>5.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blackassign0003</td>\n",
              "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>0.220339</td>\n",
              "      <td>0.097844</td>\n",
              "      <td>18.859649</td>\n",
              "      <td>0.625116</td>\n",
              "      <td>7.793906</td>\n",
              "      <td>18.859649</td>\n",
              "      <td>672</td>\n",
              "      <td>5693</td>\n",
              "      <td>2.439294</td>\n",
              "      <td>12</td>\n",
              "      <td>6.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blackassign0004</td>\n",
              "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
              "      <td>36</td>\n",
              "      <td>74</td>\n",
              "      <td>-0.345455</td>\n",
              "      <td>0.191304</td>\n",
              "      <td>20.442308</td>\n",
              "      <td>0.650988</td>\n",
              "      <td>8.437318</td>\n",
              "      <td>20.442308</td>\n",
              "      <td>692</td>\n",
              "      <td>5317</td>\n",
              "      <td>2.423150</td>\n",
              "      <td>5</td>\n",
              "      <td>5.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blackassign0005</td>\n",
              "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.080838</td>\n",
              "      <td>16.878049</td>\n",
              "      <td>0.608382</td>\n",
              "      <td>6.994572</td>\n",
              "      <td>16.878049</td>\n",
              "      <td>421</td>\n",
              "      <td>3007</td>\n",
              "      <td>2.140110</td>\n",
              "      <td>6</td>\n",
              "      <td>5.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>blackassign0096</td>\n",
              "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.384615</td>\n",
              "      <td>0.151751</td>\n",
              "      <td>21.264151</td>\n",
              "      <td>0.643301</td>\n",
              "      <td>8.762981</td>\n",
              "      <td>21.264151</td>\n",
              "      <td>725</td>\n",
              "      <td>4382</td>\n",
              "      <td>2.173507</td>\n",
              "      <td>3</td>\n",
              "      <td>5.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>blackassign0097</td>\n",
              "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
              "      <td>21</td>\n",
              "      <td>35</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.144703</td>\n",
              "      <td>27.175000</td>\n",
              "      <td>0.601656</td>\n",
              "      <td>11.110662</td>\n",
              "      <td>27.175000</td>\n",
              "      <td>654</td>\n",
              "      <td>3081</td>\n",
              "      <td>1.848780</td>\n",
              "      <td>6</td>\n",
              "      <td>4.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>blackassign0098</td>\n",
              "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.041237</td>\n",
              "      <td>15.800000</td>\n",
              "      <td>0.655696</td>\n",
              "      <td>6.582278</td>\n",
              "      <td>15.800000</td>\n",
              "      <td>259</td>\n",
              "      <td>1682</td>\n",
              "      <td>2.126582</td>\n",
              "      <td>0</td>\n",
              "      <td>5.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>blackassign0099</td>\n",
              "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.056911</td>\n",
              "      <td>17.657143</td>\n",
              "      <td>0.661812</td>\n",
              "      <td>7.327582</td>\n",
              "      <td>17.657143</td>\n",
              "      <td>409</td>\n",
              "      <td>1889</td>\n",
              "      <td>1.733533</td>\n",
              "      <td>4</td>\n",
              "      <td>4.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>blackassign0100</td>\n",
              "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
              "      <td>31</td>\n",
              "      <td>57</td>\n",
              "      <td>-0.295455</td>\n",
              "      <td>0.186441</td>\n",
              "      <td>29.828571</td>\n",
              "      <td>0.639847</td>\n",
              "      <td>12.187367</td>\n",
              "      <td>29.828571</td>\n",
              "      <td>668</td>\n",
              "      <td>4032</td>\n",
              "      <td>2.089253</td>\n",
              "      <td>3</td>\n",
              "      <td>5.18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-602d11ae-5425-4046-8780-64a4724355f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-602d11ae-5425-4046-8780-64a4724355f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-602d11ae-5425-4046-8780-64a4724355f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2c07209-3588-4232-bee7-3bc9af861b38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2c07209-3588-4232-bee7-3bc9af861b38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2c07209-3588-4232-bee7-3bc9af861b38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_11ddc6a3-d745-4158-97b4-914eaa5990da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Output_file')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_11ddc6a3-d745-4158-97b4-914eaa5990da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Output_file');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Output_file",
              "summary": "{\n  \"name\": \"Output_file\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"URL_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"blackassign0084\",\n          \"blackassign0054\",\n          \"blackassign0071\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\",\n          \"https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\",\n          \"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POSITIVE SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 128,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0,\n          5,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NEGATIVE SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 0,\n        \"max\": 179,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          33,\n          42,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POLARITY SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4343881080844309,\n        \"min\": -0.99999950000025,\n        \"max\": 0.999999958333335,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          0.7499999765625008,\n          -0.12328766954400452,\n          0.2777777700617286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBJECTIVITY SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05037804389044677,\n        \"min\": 0.02702702688093499,\n        \"max\": 0.33333327777778704,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          0.09536082461938038,\n          0.1266025638996754,\n          0.14470284200335182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG SENTENCE LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.186261553159664,\n        \"min\": 3.3333333333333335,\n        \"max\": 227.0,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          21.217391304347824,\n          19.867469879518072,\n          27.175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PERCENTAGE OF COMPLEX WORDS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043661172139183725,\n        \"min\": 0.4,\n        \"max\": 0.7261904761904762,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          0.6056818181818182,\n          0.6452563347083088,\n          0.6016559337626495\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FOG INDEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.47675145830496,\n        \"min\": 1.4933333333333334,\n        \"max\": 91.06475770925111,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          10.020050505050506,\n          8.850507597174461,\n          11.110662373505061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG NUMBER OF WORDS PER SENTENCE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.186261553159664,\n        \"min\": 3.3333333333333335,\n        \"max\": 227.0,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          21.217391304347824,\n          19.867469879518072,\n          27.175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COMPLEX WORD COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 380,\n        \"min\": 4,\n        \"max\": 2294,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          1095,\n          338,\n          535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WORD COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2270,\n        \"min\": 33,\n        \"max\": 14798,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          6858,\n          5398,\n          3081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SYLLABLE PER WORD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.225521362189884,\n        \"min\": 1.6338028169014085,\n        \"max\": 3.272727272727273,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          2.256844850065189,\n          2.1167192429022084,\n          2.173507462686567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PERSONAL PRONOUNS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 33,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          11,\n          9,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG WORD LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3944070603994423,\n        \"min\": 4.33,\n        \"max\": 6.32,\n        \"num_unique_values\": 68,\n        \"samples\": [\n          5.59,\n          5.25,\n          5.41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: code for converting above dataframe into \"Output Data Structure.xlsx\"\n",
        "\n",
        "Output_file.to_excel('Output Data Structure after Execution.xlsx', sheet_name='Sheet1')\n"
      ],
      "metadata": {
        "id": "ApOj7VE1LVz3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DC2wCDabjQy_",
        "NQD00DJ_9Mx1",
        "-muUXjq_BOA9",
        "0ADFRSntDDlK",
        "uoCCRiazHgx_",
        "dvYZ99k-NXCt",
        "45z-IXa_OA01",
        "V7QG0uZBQVTS",
        "cSjjEPtJqzgr",
        "asR-end7wBbS",
        "4OtAYohRyT3m"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}